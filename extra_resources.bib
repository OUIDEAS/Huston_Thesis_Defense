
@inproceedings{kohlbrecher_flexible_2011,
	address = {Kyoto, Japan},
	title = {A flexible and scalable {SLAM} system with full {3D} motion estimation},
	isbn = {978-1-61284-769-6 978-1-61284-770-2 978-1-61284-768-9},
	url = {http://ieeexplore.ieee.org/document/6106777/},
	doi = {10.1109/SSRR.2011.6106777},
	abstract = {For many applications in Urban Search and Rescue (USAR) scenarios robots need to learn a map of unknown environments. We present a system for fast online learning of occupancy grid maps requiring low computational resources. It combines a robust scan matching approach using a LIDAR system with a 3D attitude estimation system based on inertial sensing. By using a fast approximation of map gradients and a multi-resolution grid, reliable localization and mapping capabilities in a variety of challenging environments are realized. Multiple datasets showing the applicability in an embedded hand-held mapping system are provided. We show that the system is sufﬁciently accurate as to not require explicit loop closing techniques in the considered scenarios. The software is available as an open source package for ROS.},
	language = {en},
	urldate = {2020-03-06},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Safety}, {Security}, and {Rescue} {Robotics}},
	publisher = {IEEE},
	author = {Kohlbrecher, Stefan and von Stryk, Oskar and Meyer, Johannes and Klingauf, Uwe},
	month = nov,
	year = {2011},
	pages = {155--160},
}

@inproceedings{moleski_effects_2021,
	title = {Effects of {Velocity} and {Known} {Pose} {Injection} {Rate} on {Scan} {Matching} {2D} {SLAM} {Accuracy}},
	copyright = {All rights reserved},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2021-1582},
	doi = {10.2514/6.2021-1582},
	abstract = {Accurate localization estimation in a global or local frame is needed for a navigation solution which results in safe and efficient vehicle guidance. SLAM is a common approach to vehicle localization in GPS denied environments, but solutions often require odometry that may not be available to UAVs. ICP and Hector SLAM are common approaches for vehicle localization that rely on scan matching without the need for odometry, however both suffer when operating in long corridors with limited features for 2D single laser LiDAR scan matching. The present work injected localization solutions for the ICP method with known pose while the vehicle injection rate to velocity ratio was varied to explore their effects on average cross track error, accumulated position error, and to compare to Hector SLAM, another common method for scan matching based SLAM. The impact of the present work is that there has been an investigation on how vehicle velocity and known pose injection rate effect cumulative localization accuracy using scan matching ICP based SLAM techniques. Performance was measured using the cross track error and accumulative position error of ICP and Hector SLAM when compared to known vehicle position in simulation. Results may be used to identify system constraints such as maximum vehicle velocity for a successful mission completion given a known position injection rate and acceptable localization error.},
	urldate = {2021-02-01},
	booktitle = {{AIAA} {Scitech} 2021 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Moleski, Travis W. and Wilhelm, Jay},
	month = jan,
	year = {2021},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2021-1582},
}

@incollection{hutchison_hector_2014,
	address = {Berlin, Heidelberg},
	title = {Hector {Open} {Source} {Modules} for {Autonomous} {Mapping} and {Navigation} with {Rescue} {Robots}},
	volume = {8371},
	isbn = {978-3-662-44467-2 978-3-662-44468-9},
	url = {http://link.springer.com/10.1007/978-3-662-44468-9_58},
	abstract = {Key abilities for robots deployed in urban search and rescue tasks include autonomous exploration of disaster sites and recognition of victims and other objects of interest. In this paper, we present related open source software modules for the development of such complex capabilities which include hector slam for self-localization and mapping in a degraded urban environment. All modules have been successfully applied and tested originally in the RoboCup Rescue competition. Up to now they have already been re-used and adopted by numerous international research groups for a wide variety of tasks. Recently, they have also become part of the basis of a broader initiative for key open source software modules for urban search and rescue robots.},
	language = {en},
	urldate = {2020-03-06},
	booktitle = {{RoboCup} 2013: {Robot} {World} {Cup} {XVII}},
	publisher = {Springer Berlin Heidelberg},
	author = {Kohlbrecher, Stefan and Meyer, Johannes and Graber, Thorsten and Petersen, Karen and Klingauf, Uwe and von Stryk, Oskar},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Behnke, Sven and Veloso, Manuela and Visser, Arnoud and Xiong, Rong},
	year = {2014},
	doi = {10.1007/978-3-662-44468-9_58},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {624--631},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Q5E3TQVM/Kohlbrecher et al. - 2014 - Hector Open Source Modules for Autonomous Mapping .pdf:application/pdf},
}

@article{durrant-whyte_simultaneous_nodate,
	title = {Simultaneous {Localisation} and {Mapping} ({SLAM}): {Part} {I} {The} {Essential} {Algorithms}},
	abstract = {This tutorial provides an introduction to Simultaneous Localisation and Mapping (SLAM) and the extensive research on SLAM that has been undertaken over the past decade. SLAM is the process by which a mobile robot can build a map of an environment and at the same time use this map to compute it’s own location. The past decade has seen rapid and exciting progress in solving the SLAM problem together with many compelling implementations of SLAM methods. Part I of this tutorial (this paper), describes the probabilistic form of the SLAM problem, essential solution methods and signiﬁcant implementations. Part II of this tutorial will be concerned with recent advances in computational methods and new formulations of the SLAM problem for large scale and complex environments.},
	language = {en},
	author = {Durrant-Whyte, Hugh and Bailey, Tim},
	pages = {9},
}

@article{bailey_simultaneous_2006,
	title = {Simultaneous localization and mapping ({SLAM}): part {II}},
	volume = {13},
	issn = {1070-9932},
	shorttitle = {Simultaneous localization and mapping ({SLAM})},
	url = {http://ieeexplore.ieee.org/document/1678144/},
	doi = {10.1109/MRA.2006.1678144},
	language = {en},
	number = {3},
	urldate = {2020-02-20},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Bailey, T. and Durrant-Whyte, H.},
	month = sep,
	year = {2006},
	pages = {108--117},
}

@incollection{moleski_trilateration_nodate,
	title = {Trilateration {Positioning} {Using} {Hybrid} {Camera}-{LiDAR} {System}},
	copyright = {All rights reserved},
	url = {https://arc.aiaa.org/doi/abs/10.2514/6.2020-0393},
	abstract = {Accurate position estimation in a global or local frame is needed for a navigation solution which results in safe and efficient vehicle guidance. Visual identification of landmarks and laser ranging was investigated to bridge a gap between accuracy and computational needs for position estimation. Visual classification of landmarks in a scene and laser ranging was hybridized using a camera and scanning LiDAR facing the same direction. The hybrid landmark localization process was explored and performance was evaluated using computer vision from simulated environments. The hybrid method resulted in an average position error of 0.08 m in 2D, but when extended to 3D the error increased due to limited landmark separation in the third direction. The developed hybrid camera-LiDAR provided a successful position estimation for different landmark views.},
	urldate = {2021-02-01},
	booktitle = {{AIAA} {Scitech} 2020 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Moleski, Travis W. and Wilhelm, Jay},
	doi = {10.2514/6.2020-0393},
	note = {\_eprint: https://arc.aiaa.org/doi/pdf/10.2514/6.2020-0393},
}

@article{yadav_road_2018,
	title = {{ROAD} {SURFACE} {DETECTION} {FROM} {MOBILE} {LIDAR} {DATA}},
	volume = {IV-5},
	doi = {10.5194/isprs-annals-IV-5-95-2018},
	abstract = {The accurate three-dimensional road surface information is highly useful for health assessment and maintenance of roads. It is basic information for further analysis in several applications including road surface settlement, pavement condition assessment and slope collapse. Mobile LiDAR system (MLS) is frequently used now a days to collect detail road surface and its surrounding information in terms three-dimensional (3D) point cloud. Extraction of road surface from volumetric point cloud data is still in infancy stage because of heavy data processing requirement and the complexity in the road environment. The extraction of roads especially rural road, where road-curb is not present is very tedious job especially in Indian roadway settings. Only a few studies are available, and none for Indian roads, in the literature for rural road detection. The limitations of existing studies are in terms of their lower accuracy, very slow speed of data processing and detection of other objects having similar characteristics as the road surface. A fast and accurate method is proposed for LiDAR data points of road surface detection, keeping in mind the essence of road surface extraction especially for Indian rural roads. The Mobile LiDAR data in XYZI format is used as input in the proposed method. First square gridding is performed and ground points are roughly extracted. Then planar surface detection using mathematical framework of principal component analysis (PCA) is performed and further road surface points are detected using similarity in intensity and height difference of road surface pointe in their neighbourhood.
A case study was performed on the MLS data points captured along wide-street (two-lane road without curb) of 156m length along rural roadway site in the outskirt of Bengaluru city (South-West of India). The proposed algorithm was implemented on the MLS data of test site and its performance was evaluated it terms of recall, precision and overall accuracy that were 95.27\%, 98.85\% and 94.23\%, respectively. The algorithm was found computationally time efficient. A 7.6 million MLS data points of size 27.1MB from test site were processed in 24 minutes using the available computational resources. The proposed method is found to work even for worst case scenarios, i.e., complex road environments and rural roads, where road boundary is not clear and generally merged with road-side features.},
	journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Yadav, Manohar and Lohani, Bharat and Singh, Ajoy},
	month = nov,
	year = {2018},
	pages = {95--101},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/YHBPLZTP/Yadav et al. - 2018 - ROAD SURFACE DETECTION FROM MOBILE LIDAR DATA.pdf:application/pdf},
}

@article{milenkovic_roughness_2018,
	title = {Roughness {Spectra} {Derived} from {Multi}-{Scale} {LiDAR} {Point} {Clouds} of a {Gravel} {Surface}: {A} {Comparison} and {Sensitivity} {Analysis}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	shorttitle = {Roughness {Spectra} {Derived} from {Multi}-{Scale} {LiDAR} {Point} {Clouds} of a {Gravel} {Surface}},
	url = {https://www.mdpi.com/2220-9964/7/2/69},
	doi = {10.3390/ijgi7020069},
	abstract = {The roughness spectrum (i.e., the power spectral density) is a derivative of digital terrain models (DTMs) that is used as a surface roughness descriptor in many geomorphological and physical models. Although light detection and ranging (LiDAR) has become one of the main data sources for DTM calculation, it is still unknown how roughness spectra are affected when calculated from different LiDAR point clouds, or when they are processed differently. In this paper, we used three different LiDAR point clouds of a 1 m × 10 m gravel plot to derive and analyze the roughness spectra from the interpolated DTMs. The LiDAR point clouds were acquired using terrestrial laser scanning (TLS), and laser scanning from both an unmanned aerial vehicle (ULS) and an airplane (ALS). The corresponding roughness spectra are derived first as ensemble averaged periodograms and then the spectral differences are analyzed with a dB threshold that is based on the 95\% confidence intervals of the periodograms. The aim is to determine scales (spatial wavelengths) over which the analyzed spectra can be used interchangeably. The results show that one TLS scan can measure the roughness spectra for wavelengths larger than 1 cm (i.e., two times its footprint size) and up to 10 m, with spectral differences less than 0.65 dB. For the same dB threshold, the ULS and TLS spectra can be used interchangeably for wavelengths larger than about 1.2 dm (i.e., five times the ULS footprint size). However, the interpolation parameters should be optimized to make the ULS spectrum more accurate at wavelengths smaller than 1 m. The plot size was, however, too small to draw particular conclusions about ALS spectra. These results show that novel ULS data has a high potential to replace TLS for roughness spectrum calculation in many applications.},
	language = {en},
	number = {2},
	urldate = {2021-10-14},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Milenković, Milutin and Ressl, Camillo and Karel, Wilfried and Mandlburger, Gottfried and Pfeifer, Norbert},
	month = feb,
	year = {2018},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {gravel roughness, laser scanning, power spectral density, spectral slope, surface interpolation, UAV},
	pages = {69},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LK5MJ6CJ/Milenković et al. - 2018 - Roughness Spectra Derived from Multi-Scale LiDAR P.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ZZQA9D63/htm.html:text/html},
}

@article{moretto_assessing_nodate,
	title = {Assessing morphological changes in gravel-bed rivers using {LiDAR} data and colour bathymetry},
	abstract = {Estimating underwater features of channel bed surfaces without the use of bathymetric sensors results in very high levels of uncertainty. A novel approach to create more accurate and detailed Digital Terrain Models (DTMs) integrates LiDAR-derived elevations of dry surfaces, water depth of wetted areas derived from aerial photos and a predictive depth–colour relationship. This method was applied in three different sub-reaches of a northeastern Italian gravel-bed river (Brenta) before and after flood events occurred in November and December 2010 (recurrence interval: 8 and 10 years). From the data collected through channel field survey, a regression model which calculates channel depths using the correct intensity of three colour bands was implemented. LiDAR and depth points were merged and interpolated into a DTM which features an average error of ±18 cm. The morphological evolution and the sediment volume change calculated through a difference of DTMs shows deposition and erosion areas, indicating a deficit which reduces as it goes downstream.},
	language = {en},
	author = {Moretto, J and Rigon, E and Mao, L and Delai, F and Picco, L and Lenzi, M A},
	pages = {9},
	file = {Moretto et al. - Assessing morphological changes in gravel-bed rive.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/DVSSPCHZ/Moretto et al. - Assessing morphological changes in gravel-bed rive.pdf:application/pdf},
}

@article{anderson_gravel_2013,
	title = {The {Gravel} {Pit} {Lidar}-{Intensity} {Imagery} {Dataset}},
	abstract = {This dataset contains intensity and range data collected using a high-framerate, two-axis scanning lidar over ten individual traversals of the same 1.1km path. The experiment was conducted over a full diurnal cycle at a planetary analogue in Sudbury, Ontario, Canada and should be of interest to researchers who develop algorithms for visual odometry, simultaneous localization and mapping (SLAM) or place recognition in three-dimensional, unstructured, and natural environments. Catering to the strength of state-of-the-art SLAM techniques, this dataset creates ample opportunity for loop closure; in addition to having multiple traversals of the same path, the trajectory was speciﬁcally chosen to include both small- and large-scale loops. The lidar scans were taken with a 480×360 resolution at 2Hz, while driving roughly 0.3-0.4 meters per second; therefore, one of the challenges in using this dataset is to compensate for the motion distortion present in the data (resulting from the ‘rolling-shutter’ effect). Ground truth position is provided by means of a Thales DG-16 Differential GPS unit.},
	language = {en},
	author = {Anderson, Sean and McManus, Colin and Dong, Hang and Beerepoot, Erik and Barfoot, Timothy D},
	year = {2013},
	pages = {7},
	file = {Anderson et al. - 2013 - The Gravel Pit Lidar-Intensity Imagery Dataset.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/27X2IQEC/Anderson et al. - 2013 - The Gravel Pit Lidar-Intensity Imagery Dataset.pdf:application/pdf},
}

@article{kaasalainen_radiometric_2009,
	title = {Radiometric {Calibration} of {LIDAR} {Intensity} {With} {Commercially} {Available} {Reference} {Targets}},
	volume = {47},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2008.2003351},
	abstract = {We present a new approach for radiometric calibration of light detection and ranging (LIDAR) intensity data and demonstrate an application of this method to natural targets. The method is based on 1) using commercially available sand and gravel as reference targets and 2) the calibration of these reference targets in the laboratory conditions to know their backscatter properties. We have investigated the target properties crucial for accurate and consistent reflectance calibration and present a set of ideal targets easily available for calibration purposes. The first results from LIDAR-based brightness measurement of grass and sand show that the gravel-based calibration approach works in practice, is cost effective, and produces statistically meaningful results: Comparison of results from two separate airborne laser scanning campaigns shows that the relative calibration produces repeatable reflectance values.},
	number = {2},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Kaasalainen, Sanna and Hyyppa, Hannu and Kukko, Antero and Litkey, Paula and Ahokas, Eero and Hyyppa, Juha and Lehner, Hubert and Jaakkola, Anttoni and Suomalainen, Juha and Akujarvi, Altti and Kaasalainen, Mikko and Pyysalo, Ulla},
	month = feb,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Backscatter, Brightness, Calibration, Costs, Hyperspectral sensors, laser measurements, laser radar, Laser radar, laser radiation effects, Laser theory, Radiometry, Reflectivity, remote sensing, Remote sensing},
	pages = {588--598},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PTI2YXIF/4689353.html:text/html},
}

@misc{a_automatic_nodate,
	title = {Automatic {Road} {Vector} {Extraction} for {Mobile} {Mapping} {Systems}},
	abstract = {ABSTRACT: Land-based mobile mapping systems have yielded an enormous time saving in capturing road networks and their surrounding. However, the manual extraction of the road information from the mobile mapping data is still a time-consuming task. This paper presents ARVEE (Automated Road Geometry Vectors Extraction Engine), a robust automatic road geometry extraction system developed by Absolute Mapping Solution Inc. (AMS). The extracted road information includes 3D continuous lane lines, road edges as well as lane lines attributes. There are three innovations in this work. First, all the visible lane lines in the georeferenced image sequences are extracted, instead of only extracting the central lane line or the nearby lane line pair. Second, lane line attributes are recognized, so the output is a functional description of the road geometry. Third, the output is an absolute-georeferenced model of lane lines in mapping coordinates, and is directly compatible to GIS databases. ARVEE includes four steps: First, extracting linear features in each image. Second, extracting, filtering and grouping linear features into lane line segments (LLS) based on their geometric and radiometric characteristics. Third, linking the LLSs into long lane lines 3D model using Multiple-Hypothesis Analysis (MHA). Finally, classifying each lane line into a lane line type based on the synthetic analysis of the included LLSs ’ features. The system has been tested on large number of VISAT ™ mobile mapping data. The experiments on massive real MMS data sets demonstrate that ARVEE can deliver accurate and robust 3D continuous functional road geometry model. Full automatic processing result from ARVEE can replace most of the human efforts in road geometry modelling. 1.},
	author = {A, Wang Cheng and B, T. Hassan and B, N. El-sheimy and B, M. Lavigne},
	file = {Citeseer - Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/77P8IAKW/A et al. - Automatic Road Vector Extraction for Mobile Mappin.pdf:application/pdf;Citeseer - Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/HKIVMD85/summary.html:text/html},
}

@inproceedings{hervieu_road_2013,
	title = {Road side detection and reconstruction using {LIDAR} sensor},
	doi = {10.1109/IVS.2013.6629637},
	abstract = {Road edge localization is key knowledge for automatic road modeling and hence, in the field of autonomous vehicles. In this paper, we investigate the case of road border detection using LIDAR data. The aim is to propose a system recognizing curbs and curb ramps and to reconstruct the missing information in case of occlusion. A prediction/estimation process (inspired by Kalman filter models) has been analyzed. The map of angle deviation to ground normal is considered as a feature set, helping to characterize efficiently curbs while curb ramps and occluded curbs have been handled with the proposed model. Such a method may be used for both road map modeling and driver-assistance systems. A user interface scheme has also been described, providing an effective tool for semi-automatic processing of a large amount of data.},
	booktitle = {2013 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Hervieu, Alexandre and Soheilian, Bahman},
	month = jun,
	year = {2013},
	note = {ISSN: 1931-0587},
	keywords = {Laser radar, Computational modeling, Estimation, Image edge detection, Predictive models, Roads, Three-dimensional displays},
	pages = {1247--1252},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/MF7ZBNTI/6629637.html:text/html},
}

@misc{noauthor_radiometric_nodate,
	title = {Radiometric {Calibration} of {LIDAR} {Intensity} {With} {Commercially} {Available} {Reference} {Targets} {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/abstract/document/4689353},
	urldate = {2021-10-14},
}

@article{ibrahim_curb-based_2012,
	title = {Curb-based street floor extraction from mobile terrestrial lidar point cloud},
	volume = {39},
	doi = {10.5194/isprsarchives-XXXIX-B5-193-2012},
	abstract = {Mobile terrestrial laser scanners (MTLS) produce huge 3D point clouds describing the terrestrial surface, from which objects like
different street furniture can be generated. Extraction and modelling of the street curb and the street floor from MTLS point clouds
is important for many applications such as right-of-way asset inventory, road maintenance and city planning. The proposed pipeline
for the curb and street floor extraction consists of a sequence of five steps: organizing the 3D point cloud and nearest neighbour
search; 3D density-based segmentation to segment the ground; morphological analysis to refine out the ground segment; derivative
of Gaussian filtering to detect the curb; solving the travelling salesman problem to form a closed polygon of the curb and point-inpolygon
test to extract the street floor. Two mobile laser scanning datasets of different scenes are tested with the proposed pipeline.
The results of the extracted curb and street floor are evaluated based on a truth data. The obtained detection rates for the extracted
street floor for the datasets are 95\% and 96.53\%. This study presents a novel approach to the detection and extraction of the road
curb and the street floor from unorganized 3D point clouds captured by MTLS. It utilizes only the 3D coordinates of the point cloud.},
	journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
	author = {Ibrahim, S. and Lichti, D.},
	month = jul,
	year = {2012},
	pages = {193--198},
	file = {Full Text:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/YAVGSPER/Ibrahim and Lichti - 2012 - Curb-based street floor extraction from mobile ter.pdf:application/pdf},
}

@article{jalayer_comprehensive_2014,
	title = {A {Comprehensive} {Assessment} of {Highway} {Inventory} {Data} {Collection} {Methods}},
	doi = {10.5399/OSU/JTRF.53.2.4219},
	abstract = {This study evaluated existing highway inventory methods through a nationwide survey and a field trial of identified promising highway inventory data collection (HIDC) methods on various types of highway segments to characterize the capability of existing methods for collecting highway Inventory data vital to the implementation of the recently published HSM. The implementation of the Highway Safety Manual (HSM) at the state level has the potential to allow transportation agencies to proactively address safety concerns. However, the widespread utilization of HSM faces significant barriers as many state departments of transportations (DOTs) do not have sufficient HSM-required highway inventory data. Many techniques have been utilized by state DOTs and local agencies to collect highway inventory data for other purposes. Nevertheless, it is unknown which of these methods or any combination of them is capable of efficiently collecting the required dataset while minimizing cost and safety concerns. The focus of this study is to characterize the capability of existing methods for collecting highway inventory data vital to the implementation of the recently published HSM. More specifically, this study evaluated existing highway inventory methods through a nationwide survey and a field trial of identified promising highway inventory data collection (HIDC) methods on various types of highway segments. A comparative analysis was conducted to present an example on how to incorporate weights provided by state DOT stakeholders to select the most suitable HIDC method for the specific purpose.},
	author = {Jalayer, M. and Zhou, Huaguo and Gong, J. and Hu, Shunfu and Grinter, M.},
	year = {2014},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/P7KSS6KD/Jalayer et al. - 2014 - A Comprehensive Assessment of Highway Inventory Da.pdf:application/pdf},
}

@inproceedings{jiangui_method_2011,
	title = {A method for main road extraction from airborne {LiDAR} data in urban area},
	doi = {10.1109/ICECC.2011.6066443},
	abstract = {A method for the automatic main road extraction in urban area from airborne LiDAR (Light Detection And Ranging) data is proposed. Elevation and intensity information are used to classify road points from the raw airborne LiDAR point clouds. Firstly, the adaptive TIN (Triangulated Irregular Network) model filtering algorithm is utilized to classify the LiDAR point clouds into ground and non-ground point clouds. Secondly, the ground point clouds are classified into candidate road and non-road point clouds by intensity information. Lastly, the constrained Delaunay TIN of candidate road point clouds is constructed to improve the accuracy of classification and then the road contour is extracted from the road points image. Experimental results show that the method can extract the main road of urban area effectively.},
	booktitle = {2011 {International} {Conference} on {Electronics}, {Communications} and {Control} ({ICECC})},
	author = {Jiangui, Peng and Guang, Gao},
	month = sep,
	year = {2011},
	keywords = {Laser radar, Remote sensing, Roads, Airborne LiDAR, constrained Delaunay TIN(CD-TIN), Data mining, Filtering algorithms, intensity, point clouds, road, Tin, Urban areas},
	pages = {2425--2428},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/EY5RPV64/6066443.html:text/html},
}

@article{kavzoglu_mapping_2009,
	title = {Mapping urban road infrastructure using remotely sensed images},
	volume = {30},
	doi = {10.1080/01431160802639582},
	abstract = {Comprehensive and accurate information on the conditions of the road infrastructure is essential for effective management and planning of the road network, especially in cities facing serious traffic congestion problems, as in the city of Istanbul, Turkey. One of the most important services of the local authorities is the rehabilitation of road surfaces. Asphalt resurfacing is carried out to renew the road surface and restore its resistance to weathered and traffic worn pavements. Today, the determination of pavement surface conditions is usually carried out through visual inspections by the experts and interpretation of in situ photographs/videos. In this study, an investigation has been made to understand the spectral behaviour of the asphalt in terms of its contents and age, also to discover the feasibility of using widely available satellite sensors in the determination of road surface conditions. Two datasets in the study area from D‐100 road and TEM highway were used to examine asphalt road aging and deterioration. The changes to the conditions of the roads were detected using multispectral IKONOS images and ground spectral measurements for asphalt samples were obtained using an Analytical Spectral Devices full range (ASD FR) instrument in a laboratory environment. It was found that the road deformations mainly occur in areas where vehicles reduce or increase their speeds suddenly. Road sections just before toll booths and junctions are found to be more prone to deformations. IKONOS images can be effectively used to determine the condition of the asphalt pixels.},
	journal = {International Journal of Remote Sensing},
	author = {Kavzoglu, Taskin and Sen, Yunus and Cetin, Mufit},
	month = apr,
	year = {2009},
	pages = {1759--1769},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6NPJ6LF9/Kavzoglu et al. - 2009 - Mapping urban road infrastructure using remotely s.pdf:application/pdf},
}

@article{lehtomaki_detection_2010,
	title = {Detection of {Vertical} {Pole}-{Like} {Objects} in a {Road} {Environment} {Using} {Vehicle}-{Based} {Laser} {Scanning} {Data}},
	volume = {2},
	doi = {10.3390/rs2030641},
	abstract = {Accurate road environment information is needed in applications such as road maintenance and virtual 3D city modelling. Vehicle-based laser scanning (VLS) can produce dense point clouds from large areas efficiently from which the road and its environment can be modelled in detail. Pole-like objects such as traffic signs, lamp posts and tree trunks are an important part of road environments. An automatic method was developed for the extraction of pole-like objects from VLS data. The method was able to find 77.7\% of the poles which were found by a manual investigation of the data. Correctness of the detection was 81.0\%.},
	journal = {Remote Sensing},
	author = {Lehtomäki, Matti and Jaakkola, Anttoni and Hyyppä, Juha and Kukko, Antero and Kaartinen, Harri},
	month = mar,
	year = {2010},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/W9SIQ2ER/Lehtomäki et al. - 2010 - Detection of Vertical Pole-Like Objects in a Road .pdf:application/pdf},
}

@article{lien_recognizing_2012,
	title = {Recognizing the road points and road marks from mobile {LiDAR} point clouds},
	volume = {2},
	abstract = {Mobile lidar system is a cost-effective way to acquire spatial data in the urban area effectively. It can be used to generate a detailed street-level road model. As the need for Location Based Service (LBS) is increasing, the demand of understanding the city structure is growing up rapidly as well. For this reason, street-level road model is one of the most important elements to connect the geospatial objects in the urban area. The purpose of this paper is to extract the 3D road points and road marks from mobile lidar system effectively. The major works include road points selection and road marks extraction. In the road points selection, we select the lowest point as potential ground points from all points using elevation threshold. Then, we use the cubic curve fitting and point-to-curve distance to extract road points. It can remove non-ground points like cars and pedestrians. In the road marks extraction, we generate an intensity image by the interpolation of lidar intensity and create the road marking template for matching. Then, we extract location of road marks from the point clouds based on SIFT (Scale-invariant feature transform) matching. The test data acquired by Riegl VMX-250 system is located in Chiu-Chung Road in Taipei city. The accuracy of data is better than 10cm. The pixel size of intensity image is 7.5cm. The experiment results show that this method can extract ground points correctly. However, only limited road mark can be found in the preliminary result. The descriptors of the keypoints have a great effect on performance in matching.},
	author = {Lien, Y.-N and Teo, T.-A and Chen, C.-T and Huang, P.-Y},
	month = jan,
	year = {2012},
	pages = {1054--1059},
}

@article{liu_new_2013,
	title = {A {New} {Curb} {Detection} {Method} for {Unmanned} {Ground} {Vehicles} {Using} {2D} {Sequential} {Laser} {Data}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/13/1/1102},
	doi = {10.3390/s130101102},
	abstract = {Curb detection is an important research topic in environment perception, which is an essential part of unmanned ground vehicle (UGV) operations. In this paper, a new curb detection method using a 2D laser range finder in a semi-structured environment is presented. In the proposed method, firstly, a local Digital Elevation Map (DEM) is built using 2D sequential laser rangefinder data and vehicle state data in a dynamic environment and a probabilistic moving object deletion approach is proposed to cope with the effect of moving objects. Secondly, the curb candidate points are extracted based on the moving direction of the vehicle in the local DEM. Finally, the straight and curved curbs are detected by the Hough transform and the multi-model RANSAC algorithm, respectively. The proposed method can detect the curbs robustly in both static and typical dynamic environments. The proposed method has been verified in real vehicle experiments.},
	language = {en},
	number = {1},
	urldate = {2021-10-14},
	journal = {Sensors},
	author = {Liu, Zhao and Wang, Jinling and Liu, Daxue},
	month = jan,
	year = {2013},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {curb detection, dynamic environment, laser range finder, mapping},
	pages = {1102--1120},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7LS66YLC/Liu et al. - 2013 - A New Curb Detection Method for Unmanned Ground Ve.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/5BRVHSDM/htm.html:text/html},
}

@inproceedings{mc_elhinney_initial_2010,
	title = {Initial results from {European} {Road} {Safety} {Inspection} ({EURSI}) mobile mapping project},
	volume = {38},
	abstract = {Mobile mapping systems are becoming a popular method for collecting high quality near 3D information of terrestrial scenes. Modern mobile mapping systems can produce millions of georeferenced points per minute. These can be used to gather quantitative information about surfaces and objects. With this geospatial data it is becoming possible to segment and extract the road surface. In this paper, we will detail a novel LIDAR based road edge extraction algorithm which is applicable to both urban and rural road sections.},
	author = {Mc Elhinney, Conor and Kumar, Pankaj and Cahalane, Conor and Mccarthy, Timothy},
	month = jun,
	year = {2010},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/3VFXEG9R/Mc Elhinney et al. - 2010 - Initial results from European Road Safety Inspecti.pdf:application/pdf},
}

@article{mena_automatic_2005,
	title = {An automatic method for road extraction in rural and semi-urban areas starting from high resolution satellite imagery},
	volume = {26},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865504003265},
	doi = {10.1016/j.patrec.2004.11.005},
	abstract = {In this paper an efficient method for automatic road extraction in rural and semi-urban areas is presented. This work seeks the GIS update starting from color images and using preexisting vectorial information. As input data only the RGB bands of a satellite or aerial color image of high resolution is required. The system includes four different modules: data preprocessing; binary segmentation based on three levels of texture statistical evaluation; automatic vectorization by means of skeletal extraction; and finally a module for system evaluation. In the first module the color image is rectified and geo-referenced. The second module uses a new technique, named Texture Progressive Analysis (TPA), in order to obtain the segmented binary image. The TPA technique is developed in the evidence theory framework, and it consists in fusing information streaming from three different sources for the image. In the third module the obtained binary image is vectorized using an algorithm based on skeleton extraction techniques and morphological methods. The result is an extracted road network which is defined as a structural set of elements geometrically and topologically corrects. The fourth module is an evaluation of the procedure using a popular method. Experimental results show that this method is efficient in extracting and defining road networks from high resolution satellite and aerial imagery.},
	language = {en},
	number = {9},
	urldate = {2021-10-14},
	journal = {Pattern Recognition Letters},
	author = {Mena, J. B. and Malpica, J. A.},
	month = jul,
	year = {2005},
	keywords = {Evaluation, Evidence theory, Mathematical morphology, Road extraction, Segmentation, Skeleton, Texture analysis, Vectorization},
	pages = {1201--1220},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LNSHX69B/S0167865504003265.html:text/html},
}

@article{miyazaki_line-based_2014,
	title = {A line-based approach for precise extraction of road and curb region from mobile mapping data},
	volume = {II-5},
	issn = {2194-9050},
	url = {https://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/II-5/243/2014/},
	doi = {10.5194/isprsannals-II-5-243-2014},
	abstract = {Planar structure detection from point clouds is important process in many applications such as maintenance of infrastructure facility including roads and curbs because most artiﬁcial structures consists of planar surfaces. The Mobile Mapping System can obtain a large amount of points with traveling at a standard speed. However, in the case that the high-end laser scanning system is equipped, the distribution density of points is uneven. In the point-based method, this situation causes the problem to the method of calculating geometric information using neighborhood points. In this paper, we propose a line-based region growing method in order to detect planar structures with precise boundary from point clouds with uneven distribution density of points. The precise boundary of a planar structure is maintained by appropriately creating line segments from the input clouds. We adapt the deﬁnition of neighborhood and the estimation of the normal vector to the line-based region growing. The evaluation by comparing our result with manually extracted points shows that more than 98\% of curb points are detected. And, about 90\% of the boundary points between a road and a curb are detected with less than 0.005 meters of the distance error.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Miyazaki, R. and Yamamoto, M. and Hanamoto, E. and Izumi, H. and Harada, K.},
	month = may,
	year = {2014},
	pages = {243--250},
	file = {Miyazaki et al. - 2014 - A line-based approach for precise extraction of ro.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8CPXCRXD/Miyazaki et al. - 2014 - A line-based approach for precise extraction of ro.pdf:application/pdf},
}

@inproceedings{sock_probabilistic_2016,
	title = {Probabilistic traversability map generation using {3D}-{LIDAR} and camera},
	doi = {10.1109/ICRA.2016.7487782},
	abstract = {Estimating the traversability of rough terrain is a critical task for an outdoor mobile robot. While classifying structured environment can be learned from large number of training data, it is an extremely difficult task to learn and estimate traversability of unstructured rough terrain. Moreover, in many cases information from a single sensor may not be sufficient for estimating traversability reliably in the absence of artificial landmarks such as lane markings or curbs. Our approach estimates traversability of the terrain and build a 2D probabilistic grid map online using 3D-LIDAR and camera. The combination of LIDAR and camera is favoured in many robotic application because they provide complementary information. Our approach assumes the data captured by these two sensors are independent and build separate traversability maps, each with information captured from one sensor. Traversability estimation with vision sensor autonomously collects training data and update classifier without human intervention as the vehicle traverse the terrain. Traversability estimation with 3D-LIDAR measures the slopes of the ground to predict the traversability. Two independently built probabilistic maps are fused using Bayes' rule to improve the detection performance. This is in contrast with other methods in which each sensor performs different tasks. We have implemented the algorithm on a UGV(Unmanned Ground Vehicle) and tested our approach on a rough terrain to evaluate the detection performance.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sock, Juil and Kim, Jun and Min, Jihong and Kwak, Kiho},
	month = may,
	year = {2016},
	keywords = {Laser radar, Roads, Cameras, Probabilistic logic, Robot sensing systems, Vehicles},
	pages = {5631--5637},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/XQRM3C3T/7487782.html:text/html},
}

@article{puente_review_2013,
	title = {Review of mobile mapping and surveying technologies},
	volume = {46},
	issn = {0263-2241},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224113000730},
	doi = {10.1016/j.measurement.2013.03.006},
	abstract = {Mobile surveying is currently one of the most popular topics in the LiDAR industry. The collection of highly precise point cloud data is provided by laser scanning systems on moving platforms with an integrated navigation solution. The potential of LiDAR based mobile surveying technology is now well proven. This article introduces an analysis on the current performance of some outstanding mobile terrestrial laser scanning systems. In this work, an overview of the positioning, scanning and imaging devices integrated into these systems is also presented. As part of this study, a systematic comparison of the navigation and LiDAR specifications provided by the manufacturers is provided. Our review suggests that mobile laser scanning systems can mainly be divided into two categories (mapping and surveying) depending on their final purpose, accuracy, range and resolution requirements. A refined integrated analysis based on hardware components could be expected to cause further improvements on these results.},
	language = {en},
	number = {7},
	urldate = {2021-10-14},
	journal = {Measurement},
	author = {Puente, I. and González-Jorge, H. and Martínez-Sánchez, J. and Arias, P.},
	month = aug,
	year = {2013},
	keywords = {Laser scanning, LiDAR, Mobile mapping, Photogrammetry, Surveying},
	pages = {2127--2145},
}

@article{serna_detection_2014,
	title = {Detection, segmentation and classification of {3D} urban objects using mathematical morphology and supervised learning},
	volume = {93},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271614000872},
	doi = {10.1016/j.isprsjprs.2014.03.015},
	abstract = {We propose an automatic and robust approach to detect, segment and classify urban objects from 3D point clouds. Processing is carried out using elevation images and the result is reprojected onto the 3D point cloud. First, the ground is segmented and objects are detected as discontinuities on the ground. Then, connected objects are segmented using a watershed approach. Finally, objects are classified using SVM with geometrical and contextual features. Our methodology is evaluated on databases from Ohio (USA) and Paris (France). In the former, our method detects 98\% of the objects, 78\% of them are correctly segmented and 82\% of the well-segmented objects are correctly classified. In the latter, our method leads to an improvement of about 15\% on the classification step with respect to previous works. Quantitative results prove that our method not only provides a good performance but is also faster than other works reported in the literature.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Serna, Andrés and Marcotegui, Beatriz},
	month = jul,
	year = {2014},
	keywords = {Mathematical morphology, Segmentation, Laser scanning, 3D urban analysis, Classification, Detection, Support vector machine (SVM)},
	pages = {243--255},
	file = {Submitted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QNRLJGRY/Serna and Marcotegui - 2014 - Detection, segmentation and classification of 3D u.pdf:application/pdf},
}

@article{wu_voxel-based_2013,
	title = {A {Voxel}-{Based} {Method} for {Automated} {Identification} and {Morphological} {Parameters} {Estimation} of {Individual} {Street} {Trees} from {Mobile} {Laser} {Scanning} {Data}},
	volume = {5},
	issn = {2072-4292},
	url = {http://www.mdpi.com/2072-4292/5/2/584},
	doi = {10.3390/rs5020584},
	language = {en},
	number = {2},
	urldate = {2021-10-14},
	journal = {Remote Sensing},
	author = {Wu, Bin and Yu, Bailang and Yue, Wenhui and Shu, Song and Tan, Wenqi and Hu, Chunling and Huang, Yan and Wu, Jianping and Liu, Hongxing},
	month = jan,
	year = {2013},
	pages = {584--611},
	file = {Wu et al. - 2013 - A Voxel-Based Method for Automated Identification .pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QUVJ37ZM/Wu et al. - 2013 - A Voxel-Based Method for Automated Identification .pdf:application/pdf},
}

@article{yadav_pole-shaped_2015,
	title = {{POLE}-{SHAPED} {OBJECT} {DETECTION} {USING} {MOBILE} {LIDAR} {DATA} {IN} {RURAL} {ROAD} {ENVIRONMENTS}},
	volume = {II-3/W5},
	doi = {10.5194/isprsannals-II-3-W5-11-2015},
	abstract = {Pole-shaped objects (PSOs) located along a road play key role in road safety and planning. Automation is required for calculating the numbers of trees need to be removed and utility poles need to be relocated during rural road widening. Road-side poles are among the most frequently struck road-side objects during road-side accidents. An automatic method is therefore proposed for detecting PSOs using LiDAR point cloud captured along the roadway using Mobile LiDAR system. The proposed method is tested on the point cloud data of rural road environment in India. Dataset of study area having text file size of 1.22 GB is processed in 13 minutes resulting in completeness of 88.63 \% and correctness of 95.12 \% in identifying PSOs within 10m of the road boundary. In data of across road coverage of 5m of the road boundary, the completeness of 93.10 \% and correctness of 100\% are achieved. Poles attached with other objects, tilted poles and the poles occluded by tree branches and shrubs are detected by the proposed method.},
	journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Yadav, Manohar and Husain, A. and Singh, Ajoy and Lohani, Bharat},
	month = aug,
	year = {2015},
	pages = {11--16},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ASB44P4M/Yadav et al. - 2015 - POLE-SHAPED OBJECT DETECTION USING MOBILE LIDAR DA.pdf:application/pdf},
}

@article{kumar_automated_2013,
	title = {An automated algorithm for extracting road edges from terrestrial mobile {LiDAR} data},
	volume = {85},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271613001834},
	doi = {10.1016/j.isprsjprs.2013.08.003},
	abstract = {Terrestrial mobile laser scanning systems provide rapid and cost effective 3D point cloud data which can be used for extracting features such as the road edge along a route corridor. This information can assist road authorities in carrying out safety risk assessment studies along road networks. The knowledge of the road edge is also a prerequisite for the automatic estimation of most other road features. In this paper, we present an algorithm which has been developed for extracting left and right road edges from terrestrial mobile LiDAR data. The algorithm is based on a novel combination of two modified versions of the parametric active contour or snake model. The parameters involved in the algorithm are selected empirically and are fixed for all the road sections. We have developed a novel way of initialising the snake model based on the navigation information obtained from the mobile mapping vehicle. We tested our algorithm on different types of road sections representing rural, urban and national primary road sections. The successful extraction of road edges from these multiple road section environments validates our algorithm. These findings and knowledge provide valuable insights as well as a prototype road edge extraction tool-set, for both national road authorities and survey companies.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Kumar, Pankaj and McElhinney, Conor P. and Lewis, Paul and McCarthy, Timothy},
	month = nov,
	year = {2013},
	keywords = {LiDAR, Automation, Edge, Extraction, Terrestrial mobile},
	pages = {44--55},
	file = {Accepted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/N7BD6GS7/Kumar et al. - 2013 - An automated algorithm for extracting road edges f.pdf:application/pdf;ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G7S9P3ZI/S0924271613001834.html:text/html},
}

@article{qiu_fast_2016,
	title = {A {FAST} {AND} {ROBUST} {ALGORITHM} {FOR} {ROAD} {EDGES} {EXTRACTION} {FROM} {LIDAR} {DATA}},
	volume = {XLI-B5},
	issn = {2194-9034},
	url = {http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLI-B5/693/2016/isprs-archives-XLI-B5-693-2016.pdf},
	doi = {10.5194/isprsarchives-XLI-B5-693-2016},
	abstract = {Fast mapping of roads plays an important role in many geospatial applications, such as infrastructure planning, traffic monitoring, and driver assistance. How to extract various road edges fast and robustly is a challenging task. In this paper, we present a fast and robust algorithm for the automatic road edges extraction from terrestrial mobile LiDAR data. The algorithm is based on a key observation: most roads around edges have difference in elevation and road edges with pavement are seen in two different planes. In our algorithm, we firstly extract a rough plane based on RANSAC algorithm, and then multiple refined planes which only contains pavement are extracted from the rough plane. The road edges are extracted based on these refined planes. In practice, there is a serious problem that the rough and refined planes usually extracted badly due to rough roads and different density of point cloud. To eliminate the influence of rough roads, the technology which is similar with the difference of DSM (digital surface model) and DTM (digital terrain model) is used, and we also propose a method which adjust the point clouds to a similar density to eliminate the influence of different density. Experiments show the validities of the proposed method with multiple datasets (e.g. urban road, highway, and some rural road). We use the same parameters through the experiments and our algorithm can achieve real-time processing speeds.},
	language = {en},
	urldate = {2021-10-14},
	journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Qiu, Kaijin and Sun, Kai and Ding, Kou and Shu, Zhen},
	month = jun,
	year = {2016},
	pages = {693--698},
	file = {Qiu et al. - 2016 - A FAST AND ROBUST ALGORITHM FOR ROAD EDGES EXTRACT.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/P9ZIUCCC/Qiu et al. - 2016 - A FAST AND ROBUST ALGORITHM FOR ROAD EDGES EXTRACT.pdf:application/pdf},
}

@article{xu_real-time_2019,
	title = {A real-time road detection method based on reorganized lidar data},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0215159},
	doi = {10.1371/journal.pone.0215159},
	abstract = {Road Detection is a basic task in automated driving field, in which 3D lidar data is commonly used recently. In this paper, we propose to rearrange 3D lidar data into a new organized form to construct direct spatial relationship among point cloud, and put forward new features for real-time road detection tasks. Our model works based on two prerequisites: (1) Road regions are always flatter than non-road regions. (2) Light travels in straight lines in a uniform medium. Based on prerequisite 1, we put forward difference-between-lines feature, while ScanID density and obstacle radial map are generated based on prerequisite 2. According to our method, we construct an array of structures to store and reorganize 3D input firstly. Then, two novel features, difference-between-lines and ScanID density, are extracted, based on which we construct a consistency map and an obstacle map in Bird Eye View (BEV). Finally, the road region is extracted by fusing these two maps and refinement is used to polish up our outcome. We have carried out experiments on the public KITTI-Road benchmark, achieving one of the best performances among the lidar-based road detection methods. To further prove the efficiency of our method on unstructured road, the visual outcomes in rural areas are also proposed.},
	language = {en},
	number = {4},
	urldate = {2021-10-14},
	journal = {PLOS ONE},
	author = {Xu, Fenglei and Chen, Longtao and Lou, Jing and Ren, Mingwu},
	month = apr,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Roads, Birds, Built structures, Cartesian coordinates, Distance measurement, Lasers, Lidar, Smart materials},
	pages = {e0215159},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/S5VWK9QD/Xu et al. - 2019 - A real-time road detection method based on reorgan.pdf:application/pdf},
}

@inproceedings{manz_detection_2011,
	title = {Detection and tracking of road networks in rural terrain by fusing vision and {LIDAR}},
	doi = {10.1109/IROS.2011.6094559},
	abstract = {The ability to perceive a robot's local environment is one of the main challenges in the development of mobile ground robots. Here, we present a robust model-based approach for detection and tracking of road networks in rural terrain. To get a rich environment representation, we fuse the complementary data provided by a 3D LIDAR and an active camera platform into an accumulated, colored 3D elevation map of the terrain. Additionally, we use commercially available GIS data to get a rough idea about the geometry of the road network ahead of the robot. This way, the system is able to dynamically adjust the geometric model used within a particle filter framework for both detection and estimation of the road network's geometry. The estimation process makes use of edge- and region-based image features as well as obstacle information, all supplied by the dense terrain map. Instead of tuning the likelihood functions used within the particle filter's cue fusion concept by hand, as commonly done, we apply supervised learning techniques to derive an appropriate weighting of all features. We finally show that the proposed approach enables our ground robot MuCAR-3 to autonomously navigate on rural- and dirt-road networks.},
	booktitle = {2011 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Manz, Michael and Himmelsbach, Michael and Luettel, Thorsten and Wuensche, Hans-Joachim},
	month = sep,
	year = {2011},
	note = {ISSN: 2153-0866},
	keywords = {Laser radar, Roads, Robot sensing systems, Vehicles, Global Positioning System, Three dimensional displays},
	pages = {4562--4568},
}

@article{yadav_identification_2016,
	title = {Identification of pole-like structures from mobile lidar data of complex road environment},
	volume = {37},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431161.2016.1219462},
	doi = {10.1080/01431161.2016.1219462},
	abstract = {Pole-like structures (PLSs) located in road environment are important roadway assets. They play a vital role in road safety inspection and road planning. The use of light detection and ranging (lidar) based mobile mapping technology for mapping of PLSs is an important area of research as it holds the potential for automation. Point cloud data of rural, peri-urban, and urban road environment are used in this study, which pose special challenge in view of the complexity of terrain, unlike well-planned roads, which have been the subject of interest in existing literature for identification of PLSs. A new five-step method is proposed in this article. The first two steps, i.e. ground filtering and voxelization of filtered non-ground points, are used for data size reduction. Next three steps are used to extract PLSs from reduced data. The proposed method was tested on point cloud data of three test sites having different levels of complexities. PLSs including partially occluded pole, tilted pole, pole situated very close to other objects, and vertical pole attached to tilted pole were accurately identified. Average correctness and completeness, respectively of 92.6\% and 94.9\%, were achieved in three different complex test sites, i.e. urban, peri-urban, and rural sites, respectively. Computation complexity shows that our proposed method delivers fast and computationally efficient solution for identifying the PLSs from volumetric mobile lidar point cloud. Impact of PLSs on road safety and road planning is also addressed for these selected test sites.},
	number = {20},
	urldate = {2021-10-14},
	journal = {International Journal of Remote Sensing},
	author = {Yadav, Manohar and Lohani, Bharat and Singh, Ajai Kumar and Husain, Arshad},
	month = oct,
	year = {2016},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01431161.2016.1219462},
	pages = {4748--4777},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/KUWPRXR5/01431161.2016.html:text/html},
}

@article{yadav_extraction_2017,
	title = {Extraction of road surface from mobile {LiDAR} data of complex road environment},
	volume = {38},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431161.2017.1320451},
	doi = {10.1080/01431161.2017.1320451},
	abstract = {Three-dimensional (3D) data of roadways are frequently used for extraction of detailed roadway information which is essential for several planning and engineering applications. Recent past has seen rapid growth in utilization of mobile LiDAR system (MLS) to acquire volumetric 3D data of roadway for this purpose. MLS data are capable of capturing highly detailed road information, which is useful for road maintenance and road safety operations. The existing literature shows that road environment complexity, unevenness, and absence of raised curb limit the extraction of road information from MLS data. It must be noted that a large number of roads, especially in developing world, are characterized by these complexities and thus raise the need for a technique which can work in these road environments. Considering the above, this paper proposes a method to extract road information, where road boundary is not geometrically well-defined. The proposed method is constructed using unstructured MLS data as input and does not require any other additional data. The method is divided into three major steps, that is, MLS data structuring and ground filtering, road surface point extraction, and road boundary refinement. The first step filters ground points from input MLS data, while the second step identifies road surface points from among the ground points. The second step is designed using specific characteristics of a road, that is, topology, surface roughness, and variation of point density. Third step refines road boundary. Three test sites, quite complex with heterogeneous characteristics, were used for demonstration of the proposed method. Road surfaces of these three roadways were accurately extracted without being affected by on-road objects and absence of raised curb. Average accuracy measures like completeness, correctness, and quality were found to be 93.8\%, 98.3\%, and 92.3\%, respectively, in three test sites. Further, road boundaries of extracted road surfaces of these three test sites were refined at average completeness, correctness, and quality of 95.6\%, 97.9\%, and 93.7\%, respectively. The proposed method has shown satisfactory performance for complex roadways having road section with and without raised curb, and has potential to be employed for such road environments, which are not uncommon. Proposed method was implemented on GPU-based parallel computing framework, which significantly saved the run time in processing of MLS data of three test sites.},
	number = {16},
	urldate = {2021-10-14},
	journal = {International Journal of Remote Sensing},
	author = {Yadav, Manohar and Singh, Ajai Kumar and Lohani, Bharat},
	month = aug,
	year = {2017},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01431161.2017.1320451},
	pages = {4655--4682},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UZKLSLLG/01431161.2017.html:text/html},
}

@article{yadav_rural_2018,
	title = {Rural {Road} {Surface} {Extraction} {Using} {Mobile} {LiDAR} {Point} {Cloud} {Data}},
	volume = {46},
	issn = {0974-3006},
	url = {https://doi.org/10.1007/s12524-017-0732-4},
	doi = {10.1007/s12524-017-0732-4},
	abstract = {The existing roadway infrastructures are mostly archived with two-dimensional (2D) drawings that lack the possibility for three-dimensional (3D) interpretation and advanced 3D analysis. The mobile LiDAR system (MLS) is gaining popularity in 3D mapping applications along various types of road corridors. MLS achieves the highest data quality and completeness among the traditional roadway data collection methods. The rural roads in different countries especially in India form a substantial portion of the road network. Therefore the proper maintenance and road safety analysis of rural roads are recommended activity, which could be addressed using detailed 3D road surface information. The absence of raised curb at road boundary, and presence of complexity, heterogeneity and occlusions along the rural roadway settings restrict the use of existing studies for road surface extraction using MLS point cloud data. Therefore considering the above requirement, this research paper proposes a two-stage method. The first stage extract planar ground surfaces which are further used to filter road surface in the second stage. Global properties of road, that is, topology and smoothness and its radiometric response to laser beam of MLS are used in the second stage. MLS point cloud data of rural roadway were used to test the proposed method. The road surface points were accurately extracted without being affected by the absence of raised curb and hanging objects over the road surface, that is, tree canopies and overhead power lines. The quantitative assessment of the proposed method was performed in terms of correctness, completeness and quality, which were 96.3, 94.2, and 90.9\%, respectively.},
	language = {en},
	number = {4},
	urldate = {2021-10-14},
	journal = {Journal of the Indian Society of Remote Sensing},
	author = {Yadav, Manohar and Singh, Ajai Kumar},
	month = apr,
	year = {2018},
	pages = {531--538},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VIA664AV/Yadav and Singh - 2018 - Rural Road Surface Extraction Using Mobile LiDAR P.pdf:application/pdf},
}

@inproceedings{zhang_lidar-based_2010,
	title = {{LIDAR}-based road and road-edge detection},
	doi = {10.1109/IVS.2010.5548134},
	abstract = {In this paper, a LIDAR-based road and road-edge detection method is proposed to identify road regions and road-edges, which is an essential component of autonomous vehicles. LIDAR range data is decomposed into signals in elevation and signals projected on the ground plane. First, the elevation-based signals are processed by filtering techniques to identify the road candidate region, and by pattern recognition techniques to determine whether the candidate region is a road segment. Then, the line representation of the projected signals on the ground plane is identified and compared to a simple road model in the top-down view to determine whether the candidate region is a road segment with its road-edges. The proposed method provides fast processing speed and reliable detection performance of road and road-edge detection. The proposed framework has been verified through the DARPA Urban Challenge to show its robustness and efficiency on the winning entry Boss vehicle.},
	booktitle = {2010 {IEEE} {Intelligent} {Vehicles} {Symposium}},
	author = {Zhang, Wende},
	month = jun,
	year = {2010},
	note = {ISSN: 1931-0587},
	keywords = {Laser radar, Data mining, Algorithm design and analysis, Mobile robots, Remotely operated vehicles, Road vehicles, Robustness, Sensor arrays, Signal processing, Vehicle detection},
	pages = {845--848},
}

@article{zeybek_extraction_2021,
	title = {Extraction of {Road} {Lane} {Markings} from {Mobile} {LiDAR} {Data}},
	volume = {2675},
	doi = {10.1177/0361198120981948},
	abstract = {This study presents a method for automatic extraction of road lane markings from mobile light detection and ranging (LiDAR) data. Road lanes and traffic signs on the road surface provide safe driving for drivers and aid traffic flow movement along the highway and street. Mobile LiDAR systems acquire massive datasets very quickly in a short time. To simplify the data structure and feature extraction, it is essential for traffic management personnel to apply the right methods. Road lanes must be visible and are a major factor in road safety for drivers. In this study, a methodology is devised and implemented for the extraction of features such as dashed lines, continuous lanes, and direction arrows on the pavement from point clouds. Point cloud data was collected from the Riegl VMX-450 mobile LiDAR system. The alpha shape algorithm is implemented on a point cloud and compared with the widespread use of edge detection techniques applied for intensity-based raster images. The proposed methodology directly extracts three-dimensional and two-dimensional road features to control the quality of road markings and spatial positions with the obtained marking boundaries. State-of-the-art results are obtained and compared with manually digitized reference markings. The standard deviations were evaluated and acquired for intensity image-based and direct point cloud-based extractions, at 1.2 cm and 1.7 cm, respectively.},
	journal = {Transportation Research Record Journal of the Transportation Research Board},
	author = {Zeybek, Mustafa},
	month = jan,
	year = {2021},
}

@article{bujan_forest_2021,
	title = {Forest {Road} {Detection} {Using} {LiDAR} {Data} and {Hybrid} {Classification}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/13/3/393},
	doi = {10.3390/rs13030393},
	abstract = {Knowledge about forest road networks is essential for sustainable forest management and fire management. The aim of this study was to assess the accuracy of a new hierarchical-hybrid classification tool (HyClass) for mapping paved and unpaved forest roads with LiDAR data. Bare-earth and low-lying vegetation were also identified. For this purpose, a rural landscape (area 70 ha) in northwestern Spain was selected for study, and a road network map was extracted from the cadastral maps as the ground truth data. The HyClass tool is based on a decision tree which integrates segmentation processes at local scale with decision rules. The proposed approach yielded an overall accuracy (OA) of 96.5\%, with a confidence interval (CI) of 94.0\&ndash;97.6\%, representing an improvement over pixel-based classification (OA = 87.0\%, CI = 83.7\&ndash;89.8\%) using Random Forest (RF). In addition, with the HyClass tool, the classification precision varied significantly after reducing the original point density from 8.7 to 1 point/m2. The proposed method can provide accurate road mapping to support forest management as an alternative to pixel-based RF classification when the LiDAR point density is higher than 1 point/m2.},
	language = {en},
	number = {3},
	urldate = {2021-10-14},
	journal = {Remote Sensing},
	author = {Buján, Sandra and Guerra-Hernández, Juan and González-Ferreiro, Eduardo and Miranda, David},
	month = jan,
	year = {2021},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {forest network extraction, importance of variables, object/pixel based classification, quality measures, random forest, sensitivity analysis},
	pages = {393},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/IBJ8HB64/393.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BYRDPUUA/Buján et al. - 2021 - Forest Road Detection Using LiDAR Data and Hybrid .pdf:application/pdf},
}

@article{pollyea_experimental_2012,
	title = {Experimental evaluation of terrestrial {LiDAR}-based surface roughness estimates},
	volume = {8},
	issn = {1553-040X},
	url = {https://doi.org/10.1130/GES00733.1},
	doi = {10.1130/GES00733.1},
	abstract = {The rapid proliferation of portable, ground-based light detection and ranging (LiDAR) instruments suggests the need for additional quantitative tools complementary to the commonly invoked digital terrain model (DTM). One such metric is surface roughness, which is a measure of local-scale topographic variability and has been shown to be effective for mapping discrete morphometric features, i.e., fractures in outcrop, landslide scarps, and alluvial fan deposits, to name a few. Several surface roughness models have been proposed, the most common of which is based on the standard deviation of point distances from a reference datum, e.g., DTM panels or best-fit planes. In the present work, we evaluate the accuracy of these types of surface roughness models experimentally by constructing a surface of known roughness, acquiring terrestrial LiDAR scans of the surface at 25 dual-axis rotations, and comparing surface roughness estimates for each rotation calculated by three surface roughness models. Results indicate that a recently proposed surface roughness model based on orthogonal distance regression (ODR) planes and orthogonal point-to-plane distance measurements is generally preferred on the basis of minimum error surface roughness estimates. In addition, the effects of terrestrial LiDAR sampling errors are discussed with respect to this ODR-based surface roughness model, and several practical suggestions are made for minimizing these effects. These include (1) positioning the laser scanner at the largest reasonable distance from the scanned surface, (2) maintaining half-angles for individual scans at less than 22.5°, and (3) minimizing occlusion (shadowing) errors by using multiple, merged scans with the least possible overlap.},
	number = {1},
	urldate = {2021-10-14},
	journal = {Geosphere},
	author = {Pollyea, Ryan M. and Fairley, Jerry P.},
	month = feb,
	year = {2012},
	pages = {222--228},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/3WNKQDTI/Pollyea and Fairley - 2012 - Experimental evaluation of terrestrial LiDAR-based.pdf:application/pdf},
}

@inproceedings{kang_pothole_2017,
	title = {Pothole detection system using {2D} {LiDAR} and camera},
	doi = {10.1109/ICUFN.2017.7993890},
	abstract = {Automatic Pothole detection is important task for determining proper strategies of asphalt-surfaced pavement maintenance. In this paper, we develop a pothole detection system and method using 2D LiDAR and Camera. To improve the pothole detection accuracy, the combination of heterogeneous sensor system is used. By using 2D LiDAR, the distance and angle information of road are obtained. The pothole detection algorithm includes noise reduction pre-processing, clustering, line segment extraction, and gradient of pothole data function. Next, image-based pothole detection method is used to improve the accuracy of pothole detection and to obtain pothole shape. Image-based algorithm includes noise filtering, brightness control, binarization, addictive noise filtering, edge extraction, and object extraction and pothole detection. To show the pothole detection performance, experiments of pothole detection system using 2D LiDAR and camera are performed.},
	booktitle = {2017 {Ninth} {International} {Conference} on {Ubiquitous} and {Future} {Networks} ({ICUFN})},
	author = {Kang, Byeong-ho and Choi, Su-il},
	month = jul,
	year = {2017},
	note = {ISSN: 2165-8536},
	keywords = {Laser radar, Roads, Three-dimensional displays, Data mining, Cameras, 2D LiDAR, camera, Filtering, pothole detection, Two dimensional displays},
	pages = {744--746},
}

@article{sucgang_road_2017,
	title = {Road {Surface} {Obstacle} {Detection} using {Vision} and {LIDAR} for {Autonomous} {Vehicle}},
	abstract = {The project aims to present a system that detects and estimates road surface obstacles - potholes and speed humps using low-cost camera and LIDAR sensor. Regions are determined using histogram-based data from gray-scale image. Image segmentation and spectral clustering are used for identification and rough estimation of potholes. Speed hump; on the other hand, are detected by integrating the LIDAR measurements in time, relative to the motion of the vehicle. The algorithm is implemented in C++ with Open Source Computer Vision (OpenCV) Library. The pothole detection system can detect potholes 1.6m to 5m away from the vehicle with 86.18 percent accuracy, while the speed hump detection system can detect speed humps at an optimal distance of 4.13m with an accuracy of 98.36 percent. Errors during the detection are due to the algorithms implemented, and hardware limitations. When the two systems are cascaded, the resulting system is reliable with 80.83 percent accuracy in pothole detection, and 98.46 percent accuracy in speed hump detection. However, this is only true if the number of potholes and speed humps to be detected are minimal. The limitation of the cascaded system is imposed by the single execution capability of the processing module. Thus, to be able to use the system together, separate processing module should be used for each system.},
	language = {en},
	journal = {Hong Kong},
	author = {Sucgang, Nathalie Joy and Jr, Manuel Ramos and Arriola, Nicolette Ann},
	year = {2017},
	pages = {5},
	file = {Sucgang et al. - 2017 - Road Surface Obstacle Detection using Vision and L.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/RZHRFZQA/Sucgang et al. - 2017 - Road Surface Obstacle Detection using Vision and L.pdf:application/pdf},
}

@article{ravi_pothole_2020,
	title = {Pothole {Mapping} and {Patching} {Quantity} {Estimates} using {LiDAR}-{Based} {Mobile} {Mapping} {Systems}},
	volume = {2674},
	issn = {0361-1981},
	url = {https://doi.org/10.1177/0361198120927006},
	doi = {10.1177/0361198120927006},
	abstract = {Pavement distress or pothole mapping is important to public agencies responsible for maintaining roadways. The efficient capture of 3D point cloud data using mapping systems equipped with LiDAR eliminates the time-consuming and labor-intensive manual classification and quantity estimates. This paper proposes a methodology to map potholes along the road surface using ultra-high accuracy LiDAR units onboard a wheel-based mobile mapping system. LiDAR point clouds are processed to detect and report the location and severity of potholes by identifying the below-road 3D points pertaining to potholes, along with their depths. The surface area and volume of each detected pothole is also estimated along with the volume of its minimum bounding box to serve as an aide to choose the ideal method of repair as well as to estimate the cost of repair. The proposed approach was tested on a 10 mi-long segment on a U.S. Highway and it is observed to accurately detect potholes with varying severity and different causes. A sample of potholes detected in a 1 mi segment has been reported in the experimental results of this paper. The point clouds generated using the system are observed to have a single-track relative accuracy of less than ±1 cm and a multi-track relative accuracy of ±1–2 cm, which has been verified through comparing point clouds captured by different sensors from different tracks.},
	language = {en},
	number = {9},
	urldate = {2021-10-14},
	journal = {Transportation Research Record},
	author = {Ravi, Radhika and Habib, Ayman and Bullock, Darcy},
	month = sep,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {124--134},
}

@inproceedings{chang_detection_2005,
	address = {Cancun, Mexico},
	title = {Detection of {Pavement} {Distresses} {Using} {3D} {Laser} {Scanning} {Technology}},
	isbn = {978-0-7844-0794-3},
	url = {http://ascelibrary.org/doi/10.1061/40794%28179%29103},
	doi = {10.1061/40794(179)103},
	language = {en},
	urldate = {2021-10-14},
	booktitle = {Computing in {Civil} {Engineering} (2005)},
	publisher = {American Society of Civil Engineers},
	author = {Chang, K. T. and Chang, J. R. and Liu, J. K.},
	month = jun,
	year = {2005},
	pages = {1--11},
}

@inproceedings{korotkova_lidar_2004,
	address = {Barcelona, Spain},
	title = {Lidar model for a rough-surface target: method of partial coherence},
	shorttitle = {Lidar model for a rough-surface target},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.515086},
	doi = {10.1117/12.515086},
	urldate = {2021-10-14},
	author = {Korotkova, Olga and Andrews, Larry C. and Phillips, Ronald L.},
	editor = {Gonglewski, John D. and Stein, Karin},
	month = feb,
	year = {2004},
	pages = {49},
}

@article{rychkov_computational_2012,
	title = {Computational and methodological aspects of terrestrial surface analysis based on point clouds},
	volume = {42},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300412000465},
	doi = {10.1016/j.cageo.2012.02.011},
	abstract = {Processing of high-resolution terrestrial laser scanning (TLS) point clouds presents methodological and computational challenges before a geomorphological analysis can be carried out. We present a software library that effectively deals with billions of points and implements a simple methodology to study the surface profile and roughness. Adequate performance and scalability were achieved through the use of 64-bit memory mapped files, regular 2D grid sorting, and parallel processing. The plethora of the spatial scales found in a TLS dataset were grouped into the “ground” model at the grid scale and per cell, sub-grid surface roughness. We used centroid-thinning to build a piecewise linear ground model, and studied “detrended” standard deviation of relative elevations as a measure of surface roughness. Two applications to the point clouds from gravel river bed surveys are described. Linking empirically the standard deviation to the grain size allowed us to retrieve morphological and sedimentological models of channel topology evolution and movement of the gravel with richer quantitative results and deeper insights than the previous survey techniques.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Computers \& Geosciences},
	author = {Rychkov, Igor and Brasington, James and Vericat, Damià},
	month = may,
	year = {2012},
	keywords = {Geomorphology, Point clouds, Sedimentology, Surface roughness, TLS},
	pages = {64--70},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Z76FUL7R/S0098300412000465.html:text/html},
}

@article{lague_accurate_2013,
	title = {Accurate {3D} comparison of complex topography with terrestrial laser scanner: {Application} to the {Rangitikei} canyon ({N}-{Z})},
	volume = {82},
	issn = {0924-2716},
	shorttitle = {Accurate {3D} comparison of complex topography with terrestrial laser scanner},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271613001184},
	doi = {10.1016/j.isprsjprs.2013.04.009},
	abstract = {Surveying techniques such as terrestrial laser scanner have recently been used to measure surface changes via 3D point cloud (PC) comparison. Two types of approaches have been pursued: 3D tracking of homologous parts of the surface to compute a displacement field, and distance calculation between two point clouds when homologous parts cannot be defined. This study deals with the second approach, typical of natural surfaces altered by erosion, sedimentation or vegetation between surveys. Current comparison methods are based on a closest point distance or require at least one of the PC to be meshed with severe limitations when surfaces present roughness elements at all scales. To solve these issues, we introduce a new algorithm performing a direct comparison of point clouds in 3D. The method has two steps: (1) surface normal estimation and orientation in 3D at a scale consistent with the local surface roughness; (2) measurement of the mean surface change along the normal direction with explicit calculation of a local confidence interval. Comparison with existing methods demonstrates the higher accuracy of our approach, as well as an easier workflow due to the absence of surface meshing or Digital Elevation Model (DEM) generation. Application of the method in a rapidly eroding, meandering bedrock river (Rangitikei River canyon) illustrates its ability to handle 3D differences in complex situations (flat and vertical surfaces on the same scene), to reduce uncertainty related to point cloud roughness by local averaging and to generate 3D maps of uncertainty levels. We also demonstrate that for high precision survey scanners, the total error budget on change detection is dominated by the point clouds registration error and the surface roughness. Combined with mm-range local georeferencing of the point clouds, levels of detection down to 6mm (defined at 95\% confidence) can be routinely attained in situ over ranges of 50m. We provide evidence for the self-affine behaviour of different surfaces. We show how this impacts the calculation of normal vectors and demonstrate the scaling behaviour of the level of change detection. The algorithm has been implemented in a freely available open source software package. It operates in complex 3D cases and can also be used as a simpler and more robust alternative to DEM differencing for the 2D cases.},
	language = {en},
	urldate = {2021-10-15},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Lague, Dimitri and Brodu, Nicolas and Leroux, Jérôme},
	month = aug,
	year = {2013},
	keywords = {Geomorphology, Surface roughness, 3D change detection, Point cloud, Self-affinity, Terrestrial laser scanner},
	pages = {10--26},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VFTEAK5W/S0924271613001184.html:text/html},
}

@article{schnabel_efficient_2007,
	title = {Efficient {RANSAC} for {Point}-{Cloud} {Shape} {Detection}},
	volume = {26},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2007.01016.x},
	doi = {10.1111/j.1467-8659.2007.01016.x},
	abstract = {In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover, the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classification, meshing, simplification, approximation and reverse engineering.},
	language = {en},
	number = {2},
	urldate = {2021-10-18},
	journal = {Computer Graphics Forum},
	author = {Schnabel, R. and Wahl, R. and Klein, R.},
	year = {2007},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2007.01016.x},
	keywords = {geometry analysis, I.3.5: Computational Geometry and Object Modeling Curve, I.4.8: Scene Analysis Shape, large point-clouds, localized RANSAC, object representations, primitive shapes, shape fitting, solid, surface, Surface Fitting},
	pages = {214--226},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TLC8W7IN/Schnabel et al. - 2007 - Efficient RANSAC for Point-Cloud Shape Detection.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UEBHVV4C/j.1467-8659.2007.01016.html:text/html},
}

@article{li_improved_2017,
	title = {An {Improved} {RANSAC} for {3D} {Point} {Cloud} {Plane} {Segmentation} {Based} on {Normal} {Distribution} {Transformation} {Cells}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/9/5/433},
	doi = {10.3390/rs9050433},
	abstract = {Plane segmentation is a basic task in the automatic reconstruction of indoor and urban environments from unorganized point clouds acquired by laser scanners. As one of the most common plane-segmentation methods, standard Random Sample Consensus (RANSAC) is often used to continually detect planes one after another. However, it suffers from the spurious-plane problem when noise and outliers exist due to the uncertainty of randomly sampling the minimum subset with 3 points. An improved RANSAC method based on Normal Distribution Transformation (NDT) cells is proposed in this study to avoid spurious planes for 3D point-cloud plane segmentation. A planar NDT cell is selected as a minimal sample in each iteration to ensure the correctness of sampling on the same plane surface. The 3D NDT represents the point cloud with a set of NDT cells and models the observed points with a normal distribution within each cell. The geometric appearances of NDT cells are used to classify the NDT cells into planar and non-planar cells. The proposed method is verified on three indoor scenes. The experimental results show that the correctness exceeds 88.5\% and the completeness exceeds 85.0\%, which indicates that the proposed method identifies more reliable and accurate planes than standard RANSAC. It also executes faster. These results validate the suitability of the method.},
	language = {en},
	number = {5},
	urldate = {2021-10-18},
	journal = {Remote Sensing},
	author = {Li, Lin and Yang, Fan and Zhu, Haihong and Li, Dalin and Li, You and Tang, Lei},
	month = may,
	year = {2017},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {NDT features, normal distribution transformation, plane segmentation, point cloud, RANSAC},
	pages = {433},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/MVGNTFV3/Li et al. - 2017 - An Improved RANSAC for 3D Point Cloud Plane Segmen.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/2AHRB7VV/433.html:text/html},
}

@article{li_point_2021,
	title = {Point {Cloud} {Registration} {Based} on {One}-{Point} {RANSAC} and {Scale}-{Annealing} {Biweight} {Estimation}},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2020.3045456},
	abstract = {Point cloud registration (PCR) is an important task in photogrammetry and remote sensing, whose goal is to seek a seven-parameter similarity transformation to register a pair of point clouds. Traditional iterative closest point (ICP) variants highly rely on the initial parameters, and most of them cannot deal with cross-source (multisource) point clouds with scale changes. In this article, we propose a flexible correspondence-based PCR method, which is initial-guess free, fast, and robust. We first decompose the full seven-parameter registration problem into three subproblems, i.e., scale, rotation, and translation estimations, based on line vectors. Then, we propose a one-point random sample consensus (RANSAC) algorithm to estimate the scale and translation parameters. For the rotation estimation, we introduce a graduated optimization strategy into Tukey's biweight function and propose a scale-annealing biweight estimator. We evaluate the proposed method on both same-source and cross-source data. Results show that the proposed method is robust against over 99\% outliers and is one to two orders of magnitude faster than its competitors. The source code of our method will be made public.},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Li, Jiayuan and Hu, Qingwu and Ai, Mingyao},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Laser radar, Estimation, Three-dimensional displays, Robustness, Biweight estimator, correspondence, cross-source (multisource), Detectors, Feature extraction, point cloud registration (PCR), random sample consensus (RANSAC)., Shape},
	pages = {1--14},
}

@article{li_integrate_2020,
	title = {Integrate {Point}-{Cloud} {Segmentation} with {3D} {LiDAR} {Scan}-{Matching} for {Mobile} {Robot} {Localization} and {Mapping}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/20/1/237},
	doi = {10.3390/s20010237},
	abstract = {Localization and mapping are key requirements for autonomous mobile systems to perform navigation and interaction tasks. Iterative Closest Point (ICP) is widely applied for LiDAR scan-matching in the robotic community. In addition, the standard ICP algorithm only considers geometric information when iteratively searching for the nearest point. However, ICP individually cannot achieve accurate point-cloud registration performance in challenging environments such as dynamic environments and highways. Moreover, the computation of searching for the closest points is an expensive step in the ICP algorithm, which is limited to meet real-time requirements, especially when dealing with large-scale point-cloud data. In this paper, we propose a segment-based scan-matching framework for six degree-of-freedom pose estimation and mapping. The LiDAR generates a large number of ground points when scanning, but many of these points are useless and increase the burden of subsequent processing. To address this problem, we first apply an image-based ground-point extraction method to filter out noise and ground points. The point cloud after removing the ground points is then segmented into disjoint sets. After this step, a standard point-to-point ICP is applied into to calculate the six degree-of-freedom transformation between consecutive scans. Furthermore, once closed loops are detected in the environment, a 6D graph-optimization algorithm for global relaxation (6D simultaneous localization and mapping (SLAM)) is employed. Experiments based on publicly available KITTI datasets show that our method requires less runtime while at the same time achieves higher pose estimation accuracy compared with the standard ICP method and its variants.},
	language = {en},
	number = {1},
	urldate = {2021-10-18},
	journal = {Sensors},
	author = {Li, Xuyou and Du, Shitong and Li, Guangchun and Li, Haoyu},
	month = jan,
	year = {2020},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {6D SLAM, closed loops, dynamic environments, ground point, ICP, segmentation},
	pages = {237},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TEH7ZDZ9/Li et al. - 2020 - Integrate Point-Cloud Segmentation with 3D LiDAR S.pdf:application/pdf},
}

@inproceedings{gojcic_perfect_2019,
	address = {Long Beach, CA, USA},
	title = {The {Perfect} {Match}: {3D} {Point} {Cloud} {Matching} {With} {Smoothed} {Densities}},
	isbn = {978-1-72813-293-8},
	shorttitle = {The {Perfect} {Match}},
	url = {https://ieeexplore.ieee.org/document/8954296/},
	doi = {10.1109/CVPR.2019.00569},
	abstract = {We propose 3DSmoothNet, a full workﬂow to match 3D point clouds with a siamese deep learning architecture and fully convolutional layers using a voxelized smoothed density value (SDV) representation. The latter is computed per interest point and aligned to the local reference frame (LRF) to achieve rotation invariance. Our compact, learned, rotation invariant 3D point cloud descriptor achieves 94.9\% average recall on the 3DMatch benchmark data set [49], outperforming the state-of-the-art by more than 20 percent points with only 32 output dimensions. This very low output dimension allows for near realtime correspondence search with 0.1 ms per feature point on a standard PC. Our approach is sensor- and sceneagnostic because of SDV, LRF and learning highly descriptive features with fully convolutional layers. We show that 3DSmoothNet trained only on RGB-D indoor scenes of buildings achieves 79.0\% average recall on laser scans of outdoor vegetation, more than double the performance of our closest, learning-based competitors [49, 17, 5, 4]. Code, data and pre-trained models are available online at https://github.com/zgojcic/3DSmoothNet.},
	language = {en},
	urldate = {2021-10-18},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Gojcic, Zan and Zhou, Caifa and Wegner, Jan D. and Wieser, Andreas},
	month = jun,
	year = {2019},
	pages = {5540--5549},
	file = {Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/J3VP5Y29/Gojcic et al. - 2019 - The Perfect Match 3D Point Cloud Matching With Sm.pdf:application/pdf},
}

@inproceedings{yuan_3d_2016,
	title = {{3D} point cloud matching based on principal component analysis and iterative closest point algorithm},
	doi = {10.1109/ICALIP.2016.7846655},
	abstract = {Point cloud matching is one of the key technologies of optical three-dimensional contour measurement. Most of the point cloud matching without landmark used the iterative closest point algorithm. In order to improve the performance of the iterative closest point algorithm, the two-step iterative closest point algorithm was proposed. The improved algorithm is divided into a rough matching step and accurate matching step. Rough matching used the principal component analysis algorithm, while the fine matching used the improved iterative closest point algorithm. Compared with the classic iterative closest point algorithm, the improved algorithm can match the partial coincident point cloud. At the same time, the experiment can validate the effectiveness of the proposed algorithm.},
	booktitle = {2016 {International} {Conference} on {Audio}, {Language} and {Image} {Processing} ({ICALIP})},
	author = {Yuan, Chi and Yu, Xiaoqing and Luo, Ziyue},
	month = jul,
	year = {2016},
	keywords = {Three-dimensional displays, Algorithm design and analysis, 3D matching, Automation measuring, Convergence, Iterative closest point algorithm, iterative closet point algorithm, Principal component analysis, Quaternions, Transforms},
	pages = {404--408},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/6RVHK7MX/7846655.html:text/html},
}

@inproceedings{huang_point_2012,
	address = {Providence, RI, USA},
	title = {Point cloud matching based on {3D} self-similarity},
	isbn = {978-1-4673-1612-5 978-1-4673-1611-8 978-1-4673-1610-1},
	url = {http://ieeexplore.ieee.org/document/6238913/},
	doi = {10.1109/CVPRW.2012.6238913},
	urldate = {2021-10-18},
	booktitle = {2012 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	publisher = {IEEE},
	author = {Huang, Jing and You, Suya},
	month = jun,
	year = {2012},
	pages = {41--48},
}

@article{yang_plane_nodate,
	title = {Plane {Detection} in {Point} {Cloud} {Data}},
	abstract = {Plane detection is a prerequisite to a wide variety of vision tasks. RANdom SAmple Consensus (RANSAC) algorithm is widely used for plane detection in point cloud data. Minimum description length (MDL) principle is used to deal with several competing hypothesis. This paper presents a new approach to the plane detection by integrating RANSAC and MDL. The method could avoid detecting wrong planes due to the complex geometry of the 3D data. The paper tests the performance of proposed method on both synthetic and real data.},
	language = {en},
	author = {Yang, Michael Ying and Forstner, Wolfgang},
	pages = {16},
	file = {Yang and Forstner - Plane Detection in Point Cloud Data.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/EDJG8BJR/Yang and Forstner - Plane Detection in Point Cloud Data.pdf:application/pdf},
}

@inproceedings{yue_new_2018,
	title = {A new plane segmentation method of point cloud based on mean shift and {RANSAC}},
	doi = {10.1109/CCDC.2018.8407394},
	abstract = {Three dimensional laser scanning technology has been widely used in machine vision and reverse engineering. Plane segmentation is an important step for object recognition in the point cloud obtained by laser scanner. Traditional plane segmentation method cannot obtain a specific plane accurately when normal is unknown. This paper proposes a new method based on Mean Shift normal clustering and RANSAC with constraints and initial point to segment the specific plane whose the normal is unknown. Firstly, the point cloud is down sampled using Voxel Grid method. Secondly, the algorithm uses Mean Shift clustering method on the normal sphere to obtain the actual normal of the plane to be segmented. Thirdly, with stopping point as initial condition and actual normal as constraint, RANSAC algorithm is used to segment the specific plane. Finally this algorithm is experimentally validated in point cloud data of actual scene.},
	booktitle = {2018 {Chinese} {Control} {And} {Decision} {Conference} ({CCDC})},
	author = {Yue, Wenlong and Lu, Junguo and Zhou, Weihang and Miao, Yubin},
	month = jun,
	year = {2018},
	note = {ISSN: 1948-9447},
	keywords = {Estimation, Three-dimensional displays, RANSAC, Clustering algorithms, Covariance matrices, Mathematical model, Mean Shift, Object segmentation, Plane Segmentation, Point Cloud, Surface reconstruction},
	pages = {1658--1663},
}

@article{koguciuk_parallel_2017,
	title = {Parallel {RANSAC} for {Point} {Cloud} {Registration}},
	volume = {42},
	issn = {2300-3405},
	url = {https://www.sciendo.com/article/10.1515/fcds-2017-0010},
	doi = {10.1515/fcds-2017-0010},
	abstract = {In this paper, a project and implementation of the parallel RANSAC algorithm in CUDA architecture for point cloud registration are presented. At the beginning, a serial state of the art method with several heuristic improvements from the literature compared to basic RANSAC is introduced. Subsequently, its algorithmic parallelization and CUDA implementation details are discussed. The comparative test has proven a signiﬁcant program execution acceleration. The result is ﬁnding of the local coordinate system of the object in the scene in the near realtime conditions. The source code is shared on the Internet as a part of the Heuros system.},
	language = {en},
	number = {3},
	urldate = {2021-10-18},
	journal = {Foundations of Computing and Decision Sciences},
	author = {Koguciuk, Daniel},
	month = sep,
	year = {2017},
	pages = {203--217},
	file = {Koguciuk - 2017 - Parallel RANSAC for Point Cloud Registration.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VKTVPMBC/Koguciuk - 2017 - Parallel RANSAC for Point Cloud Registration.pdf:application/pdf},
}

@article{tarsha-kurdi_hough-transform_2007,
	title = {Hough-{Transform} and {Extended} {RANSAC} {Algorithms} for {Automatic} {Detection} of {3D} {Building} {Roof} {Planes} from {Lidar} {Data}},
	abstract = {Airborne laser scanner technique is broadly the most appropriate way to acquire rapidly and with high density 3D data over a city. Once the 3D Lidar data are available, the next task is the automatic data processing, with major aim to construct 3D building models. Among the numerous automatic reconstruction methods, the techniques allowing the detection of 3D building roof planes are of crucial importance. Three main methods arise from the literature: region growing, Hough-transform and Random Sample Consensus (RANSAC) paradigm. Since region growing algorithms are sometimes not very transparent and not homogenously applied, this paper focuses only on the Hough-transform and the RANSAC algorithm. Their principles, their pseudocode - rarely detailed in the related literature - as well as their complete analyses are presented in this paper. An analytic comparison of both algorithms, in terms of processing time and sensitivity to cloud characteristics, shows that despite the limitation encountered in both methods, RANSAC algorithm is still more efficient than the first one. Under other advantages, its processing time is negligible even when the input data size is very large. On the other hand, Hough-transform is very sensitive to the segmentation parameters values. Therefore, RANSAC algorithm has been chosen and extended to exceed its limitations. Its major limitation is that it searches to detect the best mathematical plane among 3D building point cloud even if this plane does not always represent a roof plane. So the proposed extension allows harmonizing the mathematical aspect of the algorithm with the geometry of a roof. At last, it is shown that the extended approach provides very satisfying results, even in the case of very weak point density and for different levels of building complexity. Therefore, once the roof planes are successfully detected, the automatic building modelling can be carried out.},
	language = {en},
	author = {Tarsha-Kurdi, Fayez and Landes, Tania and Grussenmeyer, Pierre},
	year = {2007},
	pages = {7},
	file = {Tarsha-Kurdi et al. - 2007 - Hough-Transform and Extended RANSAC Algorithms for.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/L8SPGNSM/Tarsha-Kurdi et al. - 2007 - Hough-Transform and Extended RANSAC Algorithms for.pdf:application/pdf},
}

@inproceedings{petrelli_repeatable_2012,
	title = {A {Repeatable} and {Efficient} {Canonical} {Reference} for {Surface} {Matching}},
	doi = {10.1109/3DIMPVT.2012.51},
	abstract = {The paper investigates on canonical references used for local surface description and matching. We formulate a novel proposal and carry out an extensive experimental evaluation addressing two major surface matching scenarios, namely shape registration and object recognition. We provide also a methodological contribution as, unlike previous work in the field, we propose a repeatability metric that captures the actual impact of the adopted local reference frame algorithm within surface matching tasks based on local 3D descriptors. Our proposal outperforms existing algorithms by a wide margin on several datasets acquired with different devices, such as laser scanners, stereo cameras and the Kinect, and in experiments relying on randomly extracted feature as well as state-of-the art key points.},
	booktitle = {Visualization {Transmission} 2012 {Second} {International} {Conference} on {3D} {Imaging}, {Modeling}, {Processing}},
	author = {Petrelli, Alioscia and Di Stefano, Luigi},
	month = oct,
	year = {2012},
	note = {ISSN: 1550-6185},
	keywords = {Feature extraction, Shape, 3D descriptor, Indexes, local reference frame, Measurement, Object recognition, Proposals, surface matching, Vectors},
	pages = {403--410},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/Z74GCHVP/6375021.html:text/html},
}

@inproceedings{petrelli_repeatable_2012-1,
	address = {Zurich, Switzerland},
	title = {A {Repeatable} and {Efficient} {Canonical} {Reference} for {Surface} {Matching}},
	isbn = {978-0-7695-4873-9 978-1-4673-4470-8},
	url = {http://ieeexplore.ieee.org/document/6375021/},
	doi = {10.1109/3DIMPVT.2012.51},
	urldate = {2021-10-18},
	booktitle = {2012 {Second} {International} {Conference} on {3D} {Imaging}, {Modeling}, {Processing}, {Visualization} \& {Transmission}},
	publisher = {IEEE},
	author = {Petrelli, Alioscia and Di Stefano, Luigi},
	month = oct,
	year = {2012},
	pages = {403--410},
}

@inproceedings{bosse_continuous_2009,
	title = {Continuous {3D} scan-matching with a spinning {2D} laser},
	doi = {10.1109/ROBOT.2009.5152851},
	abstract = {Scan-matching is a technique that can be used for building accurate maps and estimating vehicle motion by comparing a sequence of point cloud measurements of the environment taken from a moving sensor. One challenge that arises in mapping applications where the sensor motion is fast relative to the measurement time is that scans become locally distorted and difficult to align. This problem is common when using 3D laser range sensors, which typically require more scanning time than their 2D counterparts. Existing 3D mapping solutions either eliminate sensor motion by taking a “stop-and-scan” approach, or attempt to correct the motion in an open-loop fashion using odometric or inertial sensors. We propose a solution to 3D scan-matching in which a continuous 6DOF sensor trajectory is recovered to correct the point cloud alignments, producing locally accurate maps and allowing for a reliable estimate of the vehicle motion. Our method is applied to data collected from a 3D spinning lidar sensor mounted on a skid-steer loader vehicle to produce quality maps of outdoor scenes and estimates of the vehicle trajectory during the mapping sequences.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Bosse, Michael and Zlot, Robert},
	month = may,
	year = {2009},
	note = {ISSN: 1050-4729},
	keywords = {Laser radar, Vehicles, 3D mapping, Clouds, Distortion measurement, Laser noise, motion estimation, Motion estimation, Motion measurement, scan-matching, Spinning, spinning laser, Time measurement, Trajectory},
	pages = {4312--4319},
}

@article{brady_describing_1985,
	title = {Describing surfaces},
	volume = {32},
	issn = {0734-189X},
	url = {https://www.sciencedirect.com/science/article/pii/0734189X85900015},
	doi = {10.1016/0734-189X(85)90001-5},
	abstract = {This paper continues our work on visual representations of 2-dimensional surfaces. The theoretical component of our work is a study of classes of surface curves as a source of constraint on the surface on which they lie, and as a basis for describing it. We analyze bounding contours, surface intersections, lines of curvature, and asymptotes. Our experimental work investigates whether the information suggested by our theoretical study can be computed reliably and efficiently. We demonstrate algorithms that compute lines of curvature of a (Gaussian smoothed) surface; determine planar patches and umbilic regions; extract axes of surfaces of revolution and tube surfaces. We report preliminary results on adapting the curvature primal sketch algorithms of Asada and Brady [1984] to detect and describe surface intersections.},
	language = {en},
	number = {1},
	urldate = {2021-10-18},
	journal = {Computer Vision, Graphics, and Image Processing},
	author = {Brady, Michael and Ponce, Jean and Yuille, Alan and Asada, Haruo},
	month = oct,
	year = {1985},
	pages = {1--28},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BXDZUWWZ/0734189X85900015.html:text/html},
}

@article{catalucci_comparison_2018,
	title = {Comparison between point cloud processing techniques},
	volume = {127},
	issn = {0263-2241},
	url = {https://www.sciencedirect.com/science/article/pii/S0263224118305116},
	doi = {10.1016/j.measurement.2018.05.111},
	abstract = {Photomodelling is an innovative, economical and fast technique based on the same principles of photogrammetry, which leads to the creation of 3-dimensional models starting from the simple acquisition of photographs. The aim of this paper is to define performances and metrological characteristics of this new technique and to understand the full potential offered by point cloud processing software. The analytical comparison considers a structured light 3D scanning system Creaform Go Scan 50 with metrological certification as a reference, in order to verify the accuracy and precision of photomodelling, using a modified function of the ICP algorithm and spatial, volumetric and superficial comparison criteria.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Measurement},
	author = {Catalucci, Sofia and Marsili, Roberto and Moretti, Michele and Rossi, Gianluca},
	month = oct,
	year = {2018},
	keywords = {Point cloud, Iterative Closest Point algorithm, Measurement criteria, Photomodelling},
	pages = {221--226},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/88VWXV2L/S0263224118305116.html:text/html},
}

@article{droeschel_continuous_2017,
	title = {Continuous mapping and localization for autonomous navigation in rough terrain using a {3D} laser scanner},
	volume = {88},
	issn = {0921-8890},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889015303110},
	doi = {10.1016/j.robot.2016.10.017},
	abstract = {For autonomous navigation in difficult terrain, such as degraded environments in disaster response scenarios, robots are required to create a map of an unknown environment and to localize within this map. In this paper, we describe our approach to simultaneous localization and mapping that is based on the measurements of a 3D laser-range finder. We aggregate laser-range measurements by registering sparse 3D scans with a local multiresolution surfel map that has high resolution in the vicinity of the robot and coarser resolutions with increasing distance, which corresponds well to measurement density and accuracy of our sensor. By modeling measurements by surface elements, our approach allows for efficient and accurate registration and leverages online mapping and localization. The incrementally built local dense 3D maps of nearby key poses are registered against each other. Graph optimization yields a globally consistent dense 3D map of the environment. Continuous registration of local maps with the global map allows for tracking the 6D robot pose in real time. We assess the drivability of the terrain by analyzing height differences in an allocentric height map and plan cost-optimal paths. The system has been successfully demonstrated during the DARPA Robotics Challenge and the DLR SpaceBot Camp. In experiments, we evaluate accuracy and efficiency of our approach.},
	language = {en},
	urldate = {2021-10-18},
	journal = {Robotics and Autonomous Systems},
	author = {Droeschel, David and Schwarz, Max and Behnke, Sven},
	month = feb,
	year = {2017},
	keywords = {Localization, Mapping, Rough terrain},
	pages = {104--115},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BT8MELZS/S0921889015303110.html:text/html},
}

@article{brubaker_use_2013,
	title = {The {Use} of {LiDAR} {Terrain} {Data} in {Characterizing} {Surface} {Roughness} and {Microtopography}},
	volume = {2013},
	issn = {1687-7667},
	url = {https://www.hindawi.com/journals/aess/2013/891534/},
	doi = {10.1155/2013/891534},
	abstract = {The availability of light detection and ranging data (LiDAR) has resulted in a new era of landscape analysis. For example, improvements in LiDAR data resolution may make it possible to accurately model microtopography over a large geographic area; however, data resolution and processing costs versus resulting accuracy may be too costly. We examined two LiDAR datasets of differing resolutions, a low point density (0.714 points/m2 spacing) 1 m DEM available statewide in Pennsylvania and a high point density (10.28 points/m2 spacing) 1 m DEM research-grade DEM, and compared the calculated roughness between both resulting DEMs using standard deviation of slope, standard deviation of curvature, a pit fill index, and the difference between a smoothed splined surface and the original DEM. These results were then compared to field-surveyed plots and transects of microterrain. Using both datasets, patterns of roughness were identified, which were associated with different landforms derived from hydrogeomorphic features such as stream channels, gullies, and depressions. Lowland areas tended to have the highest roughness values for all methods, with other areas showing distinctive patterns of roughness values across metrics. However, our results suggest that the high-resolution research-grade LiDAR did not improve roughness modeling in comparison to the coarser statewide LiDAR. We conclude that resolution and initial point density may not be as important as the algorithm and methodology used to generate a LiDAR-derived DEM for roughness modeling purposes.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Applied and Environmental Soil Science},
	author = {Brubaker, Kristen M. and Myers, Wayne L. and Drohan, Patrick J. and Miller, Douglas A. and Boyer, Elizabeth W.},
	month = apr,
	year = {2013},
	note = {Publisher: Hindawi},
	pages = {e891534},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9F8KZY86/Brubaker et al. - 2013 - The Use of LiDAR Terrain Data in Characterizing Su.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BFWWMX9B/891534.html:text/html},
}

@article{turner_estimation_2014,
	title = {Estimation of soil surface roughness of agricultural soils using airborne {LiDAR}},
	volume = {140},
	issn = {0034-4257},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425713002885},
	doi = {10.1016/j.rse.2013.08.030},
	abstract = {Soil Surface Roughness (SR) provides a representation of surface variability which can be an important factor in a range of modelling applications such as surface water flow and sediment/nutrient transport. Moreover, it is a crucial parameter for interpreting backscatter characteristics of Synthetic Aperture Radar (SAR) for agricultural application such as near-surface soil moisture retrieval. SR is typically estimated using manual profiles of height variation along short transects (1 to 3m). However, this approach can be very time consuming and often only a small number of transects can be measured in this way, which may not be adequate to characterize the spatial variability of SR across the landscape. This study investigated the feasibility of utilising airborne Light Detection and Ranging (LiDAR) observations as an alternative for mapping SR attributes across an agricultural environment in New South Wales, Australia. To that end, SR attributes were extracted from airborne LiDAR observations and compared with those extracted from an extensive ground survey of SR making use of manual pin-profilers. Results show that LiDAR-estimates of soil profile surface heights Root Mean Square (RMS) are both accurate (compared to manual profiles) and precise (repeatable stable estimates) for fields presenting bare or fallow conditions and either presenting no row structure or as long as the orientation of the LiDAR scan line is perpendicular to the row structure. In such cases results indicated a strong correlation between LiDAR-estimated and ground-measured RMS estimates (R2{\textgreater}0.68, p{\textless}0.05), with an RMSE better than 0.81cm and bias smaller than 0.48cm from a 400m flight altitude. Moreover, estimates produced from repeat pass LiDAR datasets were consistent and highly correlated (R2 0.98) suggesting that the approach is precise and robust, provided that key tillage parameters (i.e. presence of vegetative material and row direction) can be pre-classified. LiDAR estimates of surface height RMS were shown to be accurate enough to allow the tracking of temporal changes in surface roughness due to farming activities. In contrast, LiDAR-derived surface Correlation Length (CL) estimates were not found to be a reliable proxy of the ground-measured CL.},
	language = {en},
	urldate = {2021-10-19},
	journal = {Remote Sensing of Environment},
	author = {Turner, Russell and Panciera, Rocco and Tanase, Mihai A. and Lowell, Kim and Hacker, Jorg M. and Walker, Jeffrey P.},
	month = jan,
	year = {2014},
	keywords = {Remote sensing, LiDAR, Surface roughness, Airborne},
	pages = {107--117},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G6QIQTLZ/S0034425713002885.html:text/html},
}

@article{campbell_lidar-based_2017,
	title = {A {LiDAR}-based analysis of the effects of slope, vegetation density, and ground surface roughness on travel rates for wildland firefighter escape route mapping},
	volume = {26},
	issn = {1049-8001},
	url = {http://www.publish.csiro.au/?paper=WF17031},
	doi = {10.1071/WF17031},
	abstract = {Escape routes are essential components of wildland firefighter safety, providing pre-defined pathways to a safety zone. Among the many factors that affect travel rates along an escape route, landscape conditions such as slope, lowlying vegetation density, and ground surface roughness are particularly influential, and can be measured using airborne light detection and ranging (LiDAR) data. In order to develop a robust, quantitative understanding of the effects of these landscape conditions on travel rates, we performed an experiment wherein study participants were timed while walking along a series of transects within a study area dominated by grasses, sagebrush and juniper. We compared resultant travel rates to LiDAR-derived estimates of slope, vegetation density and ground surface roughness using linear mixed effects modelling to quantify the relationships between these landscape conditions and travel rates. The best-fit model revealed significant negative relationships between travel rates and each of the three landscape conditions, suggesting that, in order of decreasing magnitude, as density, slope and roughness increase, travel rates decrease. Model coefficients were used to map travel impedance within the study area using LiDAR data, which enabled mapping the most efficient routes from fire crew locations to safety zones and provided an estimate of travel time.},
	language = {en},
	number = {10},
	urldate = {2021-10-19},
	journal = {International Journal of Wildland Fire},
	author = {Campbell, Michael J. and Dennison, Philip E. and Butler, Bret W.},
	year = {2017},
	pages = {884},
	file = {Campbell et al. - 2017 - A LiDAR-based analysis of the effects of slope, ve.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/H2AYTULD/Campbell et al. - 2017 - A LiDAR-based analysis of the effects of slope, ve.pdf:application/pdf},
}

@article{shepard_roughness_2001,
	title = {The roughness of natural terrain: {A} planetary and remote sensing perspective},
	volume = {106},
	issn = {2156-2202},
	shorttitle = {The roughness of natural terrain},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2000JE001429},
	doi = {10.1029/2000JE001429},
	abstract = {We examine the various methods and parameters in common use for quantifying and reporting surface topographic “roughness.” It is shown that scale-dependent roughness parameters are almost always required, though not widely used. We suggest a method of standardizing the parameters that are computed and reported so that topographic data gathered by different workers using different field techniques can be directly and easily intercompared. We illustrate the proposed method by analyzing topographic data from 60 different surfaces gathered by five different groups and examine the information for common features. We briefly discuss the implications of our analysis for studies of planetary surface roughness, lander safety, and radar remote sensing modeling and analysis.},
	language = {en},
	number = {E12},
	urldate = {2021-10-19},
	journal = {Journal of Geophysical Research: Planets},
	author = {Shepard, Michael K. and Campbell, Bruce A. and Bulmer, Mark H. and Farr, Tom G. and Gaddis, Lisa R. and Plaut, Jeffrey J.},
	year = {2001},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2000JE001429},
	pages = {32777--32795},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TUDLXWDP/2000JE001429.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8PDI44R7/Shepard et al. - 2001 - The roughness of natural terrain A planetary and .pdf:application/pdf},
}

@article{tegowski_statistical_2016,
	title = {Statistical and {Spectral} {Features} of {Corrugated} {Seafloor} {Shaped} by the {Hans} {Glacier} in {Svalbard}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2072-4292/8/9/744},
	doi = {10.3390/rs8090744},
	abstract = {High-resolution images of the seabed obtained with the use of hydroacoustic measurements allow a detailed identification of inaccessible seabed areas such as the Hans Glacier foreland in the Hornsund Fjord on Spitsbergen. Analyses presented in the paper were carried out on a Digital Elevation Model (DEM) of the bay’s seafloor exposed in the process of deglaciation, obtained from bathymetric data recorded by a multibeam echosounder. The main objective of this study was to show the relevance of the autocorrelation length parameter used to describe the roughness of the bottom surface based on the example of seafloor postglacial forms in the Hans Glacier foreland. The resulting parameter reflects the scale of the terrain roughness, which varies between geomorphologic forms. Maps of the autocorrelation length were derived from successive tiles of the data, overlapping by 90\%. Based on this, the two-dimensional Fourier transform (2D FFT) was successively conducted, and the power spectral density and autocorrelation were calculated following the Wiener–Khinchin theorem. The thus obtained parameter describes the scale of the glacial bay seafloor roughness, which was assigned to the geomorphological features observed.},
	language = {en},
	number = {9},
	urldate = {2021-10-19},
	journal = {Remote Sensing},
	author = {Tegowski, Jaroslaw and Trzcinska, Karolina and Kasprzak, Marek and Nowak, Jaroslaw},
	month = sep,
	year = {2016},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {DEM, glacial morphology, multibeam echosounder, rough surface, seafloor, spectral and statistical properties, terrain analysis},
	pages = {744},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8SX5QR4G/Tegowski et al. - 2016 - Statistical and Spectral Features of Corrugated Se.pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/ZGFL393D/744.html:text/html},
}

@article{hegge_spectral_1996,
	title = {Spectral {Analysis} of {Geomorphic} {Time} {Series}: {Auto}-{Spectrum}},
	volume = {21},
	issn = {1096-9837},
	shorttitle = {Spectral {Analysis} of {Geomorphic} {Time} {Series}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291096-9837%28199611%2921%3A11%3C1021%3A%3AAID-ESP703%3E3.0.CO%3B2-D},
	doi = {10.1002/(SICI)1096-9837(199611)21:11<1021::AID-ESP703>3.0.CO;2-D},
	abstract = {The collection of time series data is an essential component in the investigation of earth surface processes. Spectral analysis of these time series can provide an invaluable insight into the behaviour of geophysical processes. Spectral analysis of a single time series produces an auto-spectrum which provides a representation of the amount variance of the time series as a function of frequency. Prior to spectral analysis, the time series should be plotted to identify the presence of any trends in the mean or the variance of the series, and to identify anomalies in the data which should be corrected. To satisfy the assumption of stationarity, any trend (in either the mean or variance) should be removed from the time series. Consequently, the probability density function of the time series should be plotted and compared with the Gaussian distribution. The final stage in preparing the time series for spectral analysis is to apply a taper to reduce spectral leakage and distortion of the auto-spectrum. Following the calculation of the periodogram, spectral estimates should be combined to reduce the variability associated with the estimates and thereby ensure that the autospectrum is more representative. Finally, confidence limits should be constructed around the spectral density function so that statistically significant spectral peaks (or troughs) can be identified.},
	language = {en},
	number = {11},
	urldate = {2021-10-19},
	journal = {Earth Surface Processes and Landforms},
	author = {Hegge, Bruce J. and Masselink, Gerhard},
	year = {1996},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291096-9837\%28199611\%2921\%3A11\%3C1021\%3A\%3AAID-ESP703\%3E3.0.CO\%3B2-D},
	keywords = {auto-spectrum, spectral analysis, time series},
	pages = {1021--1040},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9FPWWJY8/(SICI)1096-9837(199611)21111021AID-ESP7033.0.html:text/html;Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/HLE5I8BC/Hegge and Masselink - 1996 - Spectral Analysis of Geomorphic Time Series Auto-.pdf:application/pdf},
}

@article{united_states_department_of_transportation_bureau_of_transportation_statistics_national_2019,
	title = {National {Transportation} {Statistics} (series)},
	url = {https://rosap.ntl.bts.gov/gsearch?collection=dot:35533&type1=mods.title&fedora_terms1=National+Transportation+Statistics},
	doi = {10.21949/1503663},
	language = {en},
	urldate = {2021-11-12},
	author = {United States. Department Of Transportation. Bureau Of Transportation Statistics},
	year = {2019},
	note = {Publisher: Not Available},
}

@misc{noauthor_autonomous_nodate,
	title = {Autonomous {Vehicle} {Market} {Size} \& {Share} {Report}, 2021-2030},
	url = {https://www.grandviewresearch.com/industry-analysis/autonomous-vehicles-market},
	abstract = {The global autonomous vehicle market demand is estimated to be at approximately 6.7 thousand units in 2020 and is anticipated to expand at a CAGR of 63.1\% from 2021 to 2030. Self-driving cars, also known as autonomous vehicles (AV), are a key innovation in the automotive industry},
	language = {en},
	urldate = {2021-11-12},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/CG8AF7FF/autonomous-vehicles-market.html:text/html},
}

@article{yang_semi-automated_2013,
	title = {Semi-automated extraction and delineation of {3D} roads of street scene from mobile laser scanning point clouds},
	volume = {79},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271613000464},
	doi = {10.1016/j.isprsjprs.2013.01.016},
	abstract = {Accurate 3D road information is important for applications such as road maintenance and virtual 3D modeling. Mobile laser scanning (MLS) is an efficient technique for capturing dense point clouds that can be used to construct detailed road models for large areas. This paper presents a method for extracting and delineating roads from large-scale MLS point clouds. The proposed method partitions MLS point clouds into a set of consecutive “scanning lines”, which each consists of a road cross section. A moving window operator is used to filter out non-ground points line by line, and curb points are detected based on curb patterns. The detected curb points are tracked and refined so that they are both globally consistent and locally similar. To evaluate the validity of the proposed method, experiments were conducted using two types of street-scene point clouds captured by Optech’s Lynx Mobile Mapper System. The completeness, correctness, and quality of the extracted roads are over 94.42\%, 91.13\%, and 91.3\%, respectively, which proves the proposed method is a promising solution for extracting 3D roads from MLS point clouds.},
	language = {en},
	urldate = {2021-11-15},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Yang, Bisheng and Fang, Lina and Li, Jonathan},
	month = may,
	year = {2013},
	keywords = {3D road extraction, Curb detection, Mobile laser scanning, Moving windows filtering, Scanning lines},
	pages = {80--93},
	file = {ScienceDirect Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/9YZXK7N4/Yang et al. - 2013 - Semi-automated extraction and delineation of 3D ro.pdf:application/pdf},
}

@misc{noauthor_table_nodate,
	title = {Table {HM}-51 - {Highway} {Statistics} 2019 - {Policy} {\textbar} {Federal} {Highway} {Administration}},
	url = {https://www.fhwa.dot.gov/policyinformation/statistics/2019/hm51.cfm},
	urldate = {2021-11-15},
	file = {Table HM-51 - Highway Statistics 2019 - Policy | Federal Highway Administration:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QF9XCIJD/hm51.html:text/html},
}

@misc{noauthor_puck_nodate,

	title = {Puck Lidar Sensor, High-Value Surround Lidar},

	url = {https://velodynelidar.com/products/puck/},

	abstract = {Velodyne's Puck lidar sensor (previously VLP-16) is the highest value sensor on the market, providing reliability, power efficiency and a surround view.},

	language = {en},

	urldate = {2021-11-16},

	journal = {Velodyne Lidar},

	author = {Velodyne}

	month = {Nov.},

	year = {2021},

	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/BBFU5WSK/puck.html:text/html},

}

@article{crisman_scarf_1993,
	title = {{SCARF}: a color vision system that tracks roads and intersections},
	volume = {9},
	issn = {2374-958X},
	shorttitle = {SCARF},
	doi = {10.1109/70.210794},
	abstract = {SCARF, a color vision system that recognizes difficult roads and intersections, is presented. It has been integrated into several navigation systems that drive a robot vehicle, the Navlab, on a variety of roads in many different weather conditions. SCARF recognizes roads that have degraded surfaces and edges with no lane markings in difficult shadow conditions. It also recognizes intersections with or without predictions from the navigation system. This is the first system that detects intersections in images without a priori knowledge of the intersection shape and location. SCARF uses Bayesian classification to determine a road-surface likelihood for each pixel in a reduced color image. It then evaluates a number of road and intersection candidates by matching an ideal road-surface likelihood image with the results from the Bayesian classification. The best matching candidate is passed to a path-planning system that navigates the robot vehicle on the road or intersection. The SCARF system is described in detail, results on a variety of images are presented, and Navlab test runs using SCARF are discussed.{\textless}{\textgreater}},
	number = {1},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Crisman, J.D. and Thorpe, C.E.},
	month = feb,
	year = {1993},
	note = {Conference Name: IEEE Transactions on Robotics and Automation},
	keywords = {Image edge detection, Road vehicles, Shape, Bayesian methods, Degradation, Machine vision, Navigation, Robots, Vehicle driving, Weather forecasting},
	pages = {49--58},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PGLMA9P8/210794.html:text/html},
}

@inproceedings{kenue_lanelok_1990,
	title = {Lanelok: {Detection} {Of} {Lane} {Boundaries} {And} {Vehicle} {Tracking} {Using} {Image}-{Processing} {Techniques} - {Part} {I}: {Hough}-{Transform}, {Region}-{Tracing} {And} {Correlation} {Algorithms}},
	shorttitle = {Lanelok},
	doi = {10.1117/12.969885},
	abstract = {The purpose of this study was to develop image-processing techniques for detecting lane boundaries and vehicle tracking using an on-board video camera that resulted in several algorithms which process the image of the road scene to extract the position of lane markers and estimate the location of the lane boundaries. The purpose of this study was to develop image-processing techniques for detecting lane boundaries and vehicle tracking using an on-board video camera. It resulted in several algorithms which process the image of the road scene to extract the position of lane markers and estimate the position of the lane boundaries and the position of the vehicle within the lane. The following algorithms were developed to process the camera's output: a Hough-transform algorithm, a region-tracing algorithm, and a vehicle-tracking algorithm. These algorithms were successfully tested on 3000 real road images, including some with missing and discontinuous markers. This capability to estimate lane boundaries will play a key role in the development of advanced automotive functions such as collision warning, collision avoidance and automatic vehicle-guidance.},
	booktitle = {Other {Conferences}},
	author = {Kenue, S.},
	year = {1990},
}

@inproceedings{kenue_lanelok_1990-1,
	title = {Lanelok: {Detection} {Of} {Lane} {Boundaries} {And} {Vehicle} {Tracking} {Using} {Image}-{Processing} {Techniques} -{Part} {II}: {Template} {Matching} {Algorithms}},
	volume = {1195},
	shorttitle = {Lanelok},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/1195/0000/Lanelok--Detection-Of-Lane-Boundaries-And-Vehicle-Tracking-Using/10.1117/12.969886.full},
	doi = {10.1117/12.969886},
	abstract = {Sensing lane boundaries is a core capability for advanced automotive functions such as collision warning, collision avoidance and automatic vehicle-guidance. Part I of this study described special image-processing algorithms for the detection of lane boundaries and vehicle tracking, using images from a video camera. Part II of this study describes a new algorithm for detecting lane boundaries using template matching. This technique was selected because of its speed and its ability to include additional knowledge--two characteristics which are required for real-time, on-board vehicle applications. The algorithm has been tested successfully on over 3000 frames of videotape from interstate highways I-75 and I-94.},
	urldate = {2021-11-22},
	booktitle = {Mobile {Robots} {IV}},
	publisher = {SPIE},
	author = {Kenue, Surender K.},
	month = mar,
	year = {1990},
	pages = {234--245},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7Z9N5Q5N/12.969886.html:text/html},
}

@article{pu_recognizing_2011,
	series = {Advances in {LIDAR} {Data} {Processing} and {Applications}},
	title = {Recognizing basic structures from mobile laser scanning data for road inventory studies},
	volume = {66},
	issn = {0924-2716},
	url = {https://www.sciencedirect.com/science/article/pii/S0924271611000955},
	doi = {10.1016/j.isprsjprs.2011.08.006},
	abstract = {Road safety inspection is currently carried out by time-consuming visual inspection. The latest mobile mapping systems provide an efficient technique for acquiring very dense point clouds along road corridors, so that automated procedures for recognizing and extracting structures can be developed. This paper presents a framework for structure recognition from mobile laser scanned point clouds. It starts with an initial rough classification into three larger categories: ground surface, objects on ground, and objects off ground. Based on a collection of characteristics of point cloud segments like size, shape, orientation and topological relationships, the objects on ground are assigned to more detailed classes such as traffic signs, trees, building walls and barriers. Two mobile laser scanning data sets acquired by different systems are tested with the recognition methods. Performance analyses of the test results are provided to demonstrate the applicability and limits of the methods. While poles are recognized for up to 86\%, classification into further categories requires further work and integration with imagery.},
	language = {en},
	number = {6, Supplement},
	urldate = {2021-11-22},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Pu, Shi and Rutzinger, Martin and Vosselman, George and Oude Elberink, Sander},
	month = dec,
	year = {2011},
	keywords = {Segmentation, Mobile laser scanning, Feature recognition, Point cloud processing, Road inventory},
	pages = {S28--S39},
	file = {ScienceDirect Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QV7FBHE7/Pu et al. - 2011 - Recognizing basic structures from mobile laser sca.pdf:application/pdf},
}

@article{noauthor_surface_totals_2006-2021xlsx_nodate,
	title = {Surface\_Totals\_2006-2021.xlsx},
	language = {en},
	pages = {1},
	file = {Surface_Totals_2006-2021.xlsx.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/JIFRNTFS/Surface_Totals_2006-2021.xlsx.pdf:application/pdf},
}

@misc{road_stats_2,
	title = {Office of {Highway} {Policy} {Information} - {Policy} {\textbar} {Federal} {Highway} {Administration}},
	url = {https://www.fhwa.dot.gov/policyinformation/statistics/2007/hm12.cfm},
	urldate = {2021-11-23},
	file = {Office of Highway Policy Information - Policy | Federal Highway Administration:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G6B5RZIX/hm12.html:text/html},

	year={2008}, 

	month={Oct}
}

@misc{noauthor_chapter_nodate,
	title = {{CHAPTER} 3 {ROAD} {DESIGN}},
	url = {https://www.fao.org/3/t0099e/T0099e03.htm},
	urldate = {2021-11-29},
	file = {CHAPTER 3 ROAD DESIGN:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/A8YIWD9U/T0099e03.html:text/html},
}

@article{skorseth_gravel_nodate,
	title = {Gravel {Roads}: {Maintenance} and {Design} {Manual}},
	language = {en},
	author = {Skorseth, Ken and Selim, Ali A},
	file = {Skorseth and Selim - Gravel Roads Maintenance and Design Manual.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VMKDDQQJ/Skorseth and Selim - Gravel Roads Maintenance and Design Manual.pdf:application/pdf},

	year={2020}, 

	month={Nov}
}

@article{noauthor_cost_nodate,
	title = {Cost {Estimating} {Guide} for {Road} {Construction}},
	language = {en},
	pages = {123},
	file = {Cost Estimating Guide for Road Construction.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QHTBLLLK/Cost Estimating Guide for Road Construction.pdf:application/pdf},
}

@article{sotelo_color_2004,
	title = {A {Color} {Vision}-{Based} {Lane} {Tracking} {System} for {Autonomous} {Driving} on {Unmarked} {Roads}},
	volume = {16},
	issn = {1573-7527},
	url = {https://doi.org/10.1023/B:AURO.0000008673.96984.28},
	doi = {10.1023/B:AURO.0000008673.96984.28},
	abstract = {This work describes a color Vision-based System intended to perform stable autonomous driving on unmarked roads. Accordingly, this implies the development of an accurate road surface detection system that ensures vehicle stability. Although this topic has already been documented in the technical literature by different research groups, the vast majority of the already existing Intelligent Transportation Systems are devoted to assisted driving of vehicles on marked extra urban roads and highways. The complete system was tested on the BABIECA prototype vehicle, which was autonomously driven for hundred of kilometers accomplishing different navigation missions on a private circuit that emulates an urban quarter. During the tests, the navigation system demonstrated its robustness with regard to shadows, road texture, and weather and changing illumination conditions.},
	language = {en},
	number = {1},
	urldate = {2021-12-09},
	journal = {Autonomous Robots},
	author = {Sotelo, Miguel Angel and Rodriguez, Francisco Javier and Magdalena, Luis and Bergasa, Luis Miguel and Boquete, Luciano},
	month = jan,
	year = {2004},
	pages = {95--116},
	file = {Springer Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/QFKYVKYS/Sotelo et al. - 2004 - A Color Vision-Based Lane Tracking System for Auto.pdf:application/pdf},
}

@inproceedings{lutzeler_ems-vision_2000,
	address = {Dearborn, MI, USA},
	title = {{EMS}-vision: recognition of intersections on unmarked road networks},
	isbn = {978-0-7803-6363-2},
	shorttitle = {{EMS}-vision},
	url = {http://ieeexplore.ieee.org/document/898359/},
	doi = {10.1109/IVS.2000.898359},
	abstract = {The ability to recognize intersections enables an autonomous vehicle to navigate on road networks for performing complex missions. The paper gives the geometry model for intersections applied and their interaction with active viewing direction control. Quality measures indicate to performance monitoring processes the reliability of the estimation results. The perception module is integrated in the EMS-Vision system. Results from autonomous turnoff maneuvers, conducted on unmarked campus roads are discussed.},
	language = {en},
	urldate = {2021-12-09},
	booktitle = {Proceedings of the {IEEE} {Intelligent} {Vehicles} {Symposium} 2000 ({Cat}. {No}.{00TH8511})},
	publisher = {IEEE},
	author = {Lutzeler, M. and Dickmanns, E.D.},
	year = {2000},
	pages = {302--307},
	file = {Lutzeler and Dickmanns - 2000 - EMS-vision recognition of intersections on unmark.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/8VQQH4RV/Lutzeler and Dickmanns - 2000 - EMS-vision recognition of intersections on unmark.pdf:application/pdf},
}

@inproceedings{lutzeler_ems-vision_2000-1,
	title = {{EMS}-vision: recognition of intersections on unmarked road networks},
	shorttitle = {{EMS}-vision},
	doi = {10.1109/IVS.2000.898359},
	abstract = {The ability to recognize intersections enables an autonomous vehicle to navigate on road networks for performing complex missions. The paper gives the geometry model for intersections applied and their interaction with active viewing direction control. Quality measures indicate to performance monitoring processes the reliability of the estimation results. The perception module is integrated in the EMS-Vision system. Results from autonomous turn-off maneuvers, conducted on unmarked campus roads are discussed.},
	booktitle = {Proceedings of the {IEEE} {Intelligent} {Vehicles} {Symposium} 2000 ({Cat}. {No}.{00TH8511})},
	author = {Lutzeler, M. and Dickmanns, E.D.},
	month = oct,
	year = {2000},
	keywords = {Cameras, Road vehicles, Vehicle detection, Machine vision, Navigation, Geometry, Layout, Monitoring, Solid modeling, Vehicle dynamics},
	pages = {302--307},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LJ5C3MQX/898359.html:text/html},
}

@inproceedings{jochem_vision-based_1995,
	title = {Vision-based neural network road and intersection detection and traversal},
	volume = {3},
	doi = {10.1109/IROS.1995.525907},
	abstract = {The use of artificial neural networks in the domain of autonomous driving has produced promising results. ALVINN has shown that a neural system can drive a vehicle reliably and safely on many different types of roads, ranging from paved paths to interstate highways. The next step in the evolution of autonomous driving systems is to intelligently handle road junctions. In this paper the authors present an addition to the basic ALVINN driving system which makes autonomous detection of roads and traversal of simple intersections possible. The addition is based on geometrically modelling the world, accurately imaging interesting parts of the scene using this model, and monitoring ALVINN's response to the created image.},
	booktitle = {Proceedings 1995 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}. {Human} {Robot} {Interaction} and {Cooperative} {Robots}},
	author = {Jochem, T.M. and Pomerleau, D.A. and Thorpe, C.E.},
	month = aug,
	year = {1995},
	keywords = {Remotely operated vehicles, Road vehicles, Vehicle driving, Layout, Solid modeling, Artificial neural networks, Intelligent systems, Neural networks, Road transportation, Vehicle safety},
	pages = {344--349 vol.3},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/UHV84YHU/525907.html:text/html},
}

@article{espineira_realistic_2021,
	title = {Realistic {LiDAR} {With} {Noise} {Model} for {Real}-{Time} {Testing} of {Automated} {Vehicles} in a {Virtual} {Environment}},
	volume = {21},
	issn = {1558-1748},
	doi = {10.1109/JSEN.2021.3059310},
	abstract = {The global Connected and Autonomous Mobility industry is growing at a rapid pace. To ensure the successful adoption of connected automated mobility solutions, their safety, reliability and hence the public acceptance are paramount. It is widely known that in order to demonstrate that L3+ automated systems are safer with respect to human drivers, upwards of several millions of miles need to be driven. The only way to efficiently achieve this amount of tests in a timely manner is by using simulations and high fidelity virtual environments. Two key components of being able to test an automated system in a synthetic environment are validated sensor models and noise models for each sensor technology. In fact, the sensors are the element feeding information into the system in order to enable it to safely plan the trajectory and navigate. In this paper, we propose an innovative real-time LiDAR sensor model based on beam propagation and a probabilistic rain model, taking into account raindrop distribution and size. The model can seamlessly run in real-time, synchronised with the visual rendering, in immersive driving simulators, such as the WMG 3xD simulator. The models are developed using Unreal engine, therefore demonstrating that gaming technology can be merged with the Automated Vehicles (AVs) simulation toolchain for the creation and visualization of high fidelity scenarios and for AV accurate testing. This work can be extended to add more sensors and more noise factors or cyberattacks in real-time simulations.},
	number = {8},
	journal = {IEEE Sensors Journal},
	author = {Espineira, Juan P. and Robinson, Jonathan and Groenewald, Jakobus and Chan, Pak Hung and Donzella, Valentina},
	month = apr,
	year = {2021},
	note = {Conference Name: IEEE Sensors Journal},
	keywords = {Autonomous and automated vehicles, Laser beams, Laser radar, light detection and ranging (LiDAR), Mathematical model, noise, perception sensor, rain, Rain, real-time simulation, Real-time systems, sensor models, Sensors, Testing},
	pages = {9919--9926},
	file = {Accepted Version:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/PW6NXRPF/Espineira et al. - 2021 - Realistic LiDAR With Noise Model for Real-Time Tes.pdf:application/pdf;IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/VZVHKZFX/9354172.html:text/html},
}

@misc{noauthor_autowareai_nodate,
	title = {Autoware.{AI}},
	url = {https://www.autoware.org/autoware-ai},
	language = {en},
	urldate = {2021-12-15},
	journal = {Autoware},
	file = {Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/5XFJPDN9/autoware-ai.html:text/html},
}

@inproceedings{fernandes_road_2014,
	address = {Coimbra, Portugal},
	title = {Road {Detection} {Using} {High} {Resolution} {LIDAR}},
	isbn = {978-1-4799-6783-4},
	url = {http://ieeexplore.ieee.org/document/7007125/},
	doi = {10.1109/VPPC.2014.7007125},
	abstract = {This paper proposes a road detection approach based solely on dense 3D-LIDAR data. The approach is built up of four stages: (1) 3D-LIDAR points are projected to a 2D reference plane; then, (2) dense height maps are computed using an upsampling method; (3) applying a sliding-window technique in the upsampled maps, probability distributions of neighboring regions are compared according to a similarity measure; ﬁnally, (4) morphological operations are used to enhance performance against disturbances. Our detection approach does not depend on road marks, thus it is suitable for applications on rural areas and inner-city with unmarked roads. Experiments have been carried out in a wide variety of scenarios using the recent KITTI-ROAD benchmark [1], obtaining promising results when compared to other state-of-art approaches.},
	language = {en},
	urldate = {2021-12-15},
	booktitle = {2014 {IEEE} {Vehicle} {Power} and {Propulsion} {Conference} ({VPPC})},
	publisher = {IEEE},
	author = {Fernandes, R. and Premebida, C. and Peixoto, P. and Wolf, D. and Nunes, U.},
	month = oct,
	year = {2014},
	pages = {1--6},
	file = {Fernandes et al. - 2014 - Road Detection Using High Resolution LIDAR.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/2937QZSG/Fernandes et al. - 2014 - Road Detection Using High Resolution LIDAR.pdf:application/pdf},
}

@article{marinello_determination_2017,
	title = {Determination of forest road surface roughness by {Kinect} depth imaging},
	volume = {60},
	copyright = {All the papers published in Annals of Forest Research are available under an open access policy (Gratis Gold  Open Access Licence ), which guaranty the free (of taxes) and unlimited access, for anyone, to entire content of the all published articles. The users are free to “read, copy, distribute, print, search or refers to the full text of these articles”, as long they mention the source.  The other materials (texts, images, graphical elements presented on the Website) are protected by copyright.  The journal exerts a permanent quality check, based on an established protocol for publishing the manuscripts. The potential article to be published are evaluated (peer-review) by members of the Editorial Board or other collaborators with competences on the paper topics. The publishing of manuscript is free of charge, all the costs being supported by Forest Research and Management Institute.  More details about Open Access:  Wikipedia:  http://en.wikipedia.org/wiki/Open\_access   DOAJ:  http://www.doaj.org/oainfo},
	issn = {20652445},
	url = {http://afrjournal.org/index.php/afr/article/view/893},
	doi = {10.15287/afr.2017.893},
	abstract = {Roughness is a dynamic property of the gravel road surface that affects safety, ride comfort as well as vehicle tyre life and maintenance costs. A rapid survey of gravel road condition is fundamental for an effective maintenance planning and definition of the intervention priorities. Different non-contact techniques such as laser scanning, ultrasonic sensors and photogrammetry have recently been proposed to reconstruct three-dimensional topography of road surface and allow extraction of roughness metrics. The application of Microsoft Kinect™ depth camera is proposed and discussed here for collection of 3D data sets from gravel roads, to be implemented in order to allow quantification of surface roughness. The objectives are to: i) verify the applicability of the Kinect sensor for characterization of different forest roads, ii) identify the appropriateness and potential of different roughness parameters and iii) analyse the correlation with vibrations recoded by 3-axis accelerometers installed on different vehicles. The test took advantage of the implementation of the Kinect depth camera for surface roughness determination of 4 different forest gravel roads and one well-maintained asphalt road as reference. Different vehicles (mountain bike, off-road motorcycle, ATV vehicle, 4WD car and compact crossover) were included in the experiment in order to verify the vibration intensity when travelling on different road surface conditions. Correlations between the extracted roughness parameters and vibration levels of the tested vehicles were then verified. Coefficients of determination of between 0.76 and 0.97 were detected between average surface roughness and standard deviation of relative accelerations, with higher values in the case of lighter vehicles.},
	language = {en},
	number = {2},
	urldate = {2021-12-16},
	journal = {Annals of Forest Research},
	author = {Marinello, Francesco and Proto, Andrea Rosario and Zimbalatti, Giuseppe and Pezzuolo, Andrea and Cavalli, Raffaele and Grigolato, Stefano},
	month = nov,
	year = {2017},
	note = {Number: 2},
	pages = {217--226},
	file = {Full Text PDF:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/7Y2C2X87/Marinello et al. - 2017 - Determination of forest road surface roughness by .pdf:application/pdf;Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/TJTBQCAG/893.html:text/html},
}

@article{asvadi_3d_2016,
	title = {{3D} {Lidar}-based static and moving obstacle detection in driving environments: {An} approach based on voxels and multi-region ground planes},
	volume = {83},
	issn = {0921-8890},
	shorttitle = {{3D} {Lidar}-based static and moving obstacle detection in driving environments},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889016300483},
	doi = {10.1016/j.robot.2016.06.007},
	abstract = {Artificial perception, in the context of autonomous driving, is the process by which an intelligent system translates sensory data into an effective model of the environment surrounding a vehicle. In this paper, and considering data from a 3D-LIDAR mounted onboard an intelligent vehicle, a 3D perception system based on voxels and planes is proposed for ground modeling and obstacle detection in urban environments. The system, which incorporates time-dependent data, is composed of two main modules: (i) an effective ground surface estimation using a piecewise plane fitting algorithm and RANSAC-method, and (ii) a voxel-grid model for static and moving obstacles detection using discriminative analysis and ego-motion information. This perception system has direct application in safety systems for intelligent vehicles, particularly in collision avoidance and vulnerable road users detection, namely pedestrians and cyclists. Experiments, using point-cloud data from a Velodyne LIDAR and localization data from an Inertial Navigation System were conducted for both a quantitative and a qualitative assessment of the static/moving obstacle detection module and for the surface estimation approach. Reported results, from experiments using the KITTI database, demonstrate the applicability and efficiency of the proposed approach in urban scenarios.},
	language = {en},
	urldate = {2021-12-16},
	journal = {Robotics and Autonomous Systems},
	author = {Asvadi, Alireza and Premebida, Cristiano and Peixoto, Paulo and Nunes, Urbano},
	month = sep,
	year = {2016},
	keywords = {3D representation, LIDAR perception, Obstacle detection, Scene understanding},
	pages = {299--311},
	file = {ScienceDirect Snapshot:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/FD37XVS8/S0921889016300483.html:text/html},
}

@inproceedings{zhang_lidar-based_2010-1,
	title = {{LIDAR}-based road and road-edge detection},
	doi = {10.1109/IVS.2010.5548134},
	abstract = {In this paper, a LIDAR-based road and road-edge detection method is proposed to identify road regions and road-edges, which is an essential component of autonomous vehicles. LIDAR range data is decomposed into signals in elevation and signals projected on the ground plane. First, the elevation-based signals are processed by filtering techniques to identify the road candidate region, and by pattern recognition techniques to determine whether the candidate region is a road segment. Then, the line representation of the projected signals on the ground plane is identified and compared to a simple road model in the top-down view to determine whether the candidate region is a road segment with its road-edges. The proposed method provides fast processing speed and reliable detection performance of road and road-edge detection. The proposed framework has been verified through the DARPA Urban Challenge to show its robustness and efficiency on the winning entry Boss vehicle.},
	booktitle = {2010 {IEEE} {Intelligent} {Vehicles} {Symposium}},
	author = {Zhang, Wende},
	month = jun,
	year = {2010},
	note = {ISSN: 1931-0587},
	keywords = {Algorithm design and analysis, Data mining, Laser radar, Mobile robots, Remotely operated vehicles, Road vehicles, Robustness, Sensor arrays, Signal processing, Vehicle detection},
	pages = {845--848},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/G3XG39BK/5548134.html:text/html},
}

@inproceedings{zhao_road_2012,
	title = {Road network extraction from airborne {LiDAR} data using scene context},
	doi = {10.1109/CVPRW.2012.6238909},
	abstract = {We presented a novel procedure to extract ground road networks from airborne LiDAR data. First point clouds were separated into ground and non-ground parts, and ground roads were to be extracted from ground planes. Then, buildings and trees were distinguished in an energy minimization framework after incorporation of two new features. The separation provided supportive information for later road extractions. After that, we designed structure templates to search for roads on ground intensity images, and road widths and orientations were determined by a subsequent voting scheme. This local searching process produced road candidates only, in order to prune false positives and infer undetected roads, a scene-dependent Markov network was constructed to help infer a global road network. Combination of local template fitting and global MRF inference made extracted ground roads more accurate and complete. Finally, we extended developed methods to elevated roads extraction from non-ground points and combined them with the ground road network to formulate a whole network.},
	booktitle = {2012 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops}},
	author = {Zhao, Jiaping and You, Suya},
	month = jun,
	year = {2012},
	note = {ISSN: 2160-7516},
	keywords = {Buildings, Data mining, Feature extraction, Fitting, Laser radar, Roads, Vegetation},
	pages = {9--16},
	file = {IEEE Xplore Abstract Record:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/E87DMTAN/6238909.html:text/html},
}

@article{smadja_road_nodate,
	title = {{ROAD} {EXTRACTION} {AND} {ENVIRONMENT} {INTERPRETATION} {FROM} {LIDAR} {SENSORS}},
	abstract = {We present in this article a new vehicle dedicated to road surveying, equipped with a highly precise positioning system, 2D lidar scans and high deﬁnition color images. We focus at ﬁrst on the sensors extrinsic calibration process. Once all sensors have been positioned in the same coordinates system, 3D realistic environments can be computed and interpreted. Moreover, an original algorithm for road extraction has been developed. This two-step method is based on the local road shape and does not rely on the presence of curbs or guardrails. Different uses of the RanSaC algorithm are employed, for road sides rough estimation in the ﬁrst place, then for unlikely candidates elimination. Road boundary and center points are further processed for road width and curvature computation in order to feed a geographic information system. Finally, a simple extraction of trafﬁc signs and road markings is presented.},
	language = {en},
	author = {Smadja, Laurent and Ninot, Jerome and Gavrilovic, Thomas},
	pages = {7},
	file = {Smadja et al. - ROAD EXTRACTION AND ENVIRONMENT INTERPRETATION FRO.pdf:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/IMT2CFWY/Smadja et al. - ROAD EXTRACTION AND ENVIRONMENT INTERPRETATION FRO.pdf:application/pdf},
}

@article{chen_progressive_2019,
	title = {Progressive {LiDAR} adaptation for road detection},
	volume = {6},
	issn = {2329-9274},
	doi = {10.1109/JAS.2019.1911459},
	abstract = {Despite rapid developments in visual image-based road detection, robustly identifying road areas in visual images remains challenging due to issues like illumination changes and blurry images. To this end, LiDAR sensor data can be incorporated to improve the visual image-based road detection, because LiDAR data is less susceptible to visual noises. However, the main difficulty in introducing LiDAR information into visual image-based road detection is that LiDAR data and its extracted features do not share the same space with the visual data and visual features. Such gaps in spaces may limit the benefits of LiDAR information for road detection. To overcome this issue, we introduce a novel Progressive LiDAR adaptation-aided road detection (PLARD) approach to adapt LiDAR information into visual image-based road detection and improve detection performance. In PLARD, progressive LiDAR adaptation consists of two subsequent modules: 1) data space adaptation, which transforms the LiDAR data to the visual data space to align with the perspective view by applying altitude difference-based transformation; and 2) feature space adaptation, which adapts LiDAR features to visual features through a cascaded fusion structure. Comprehensive empirical studies on the well-known KITTI road detection benchmark demonstrate that PLARD takes advantage of both the visual and LiDAR information, achieving much more robust road detection even in challenging urban scenes. In particular, PLARD outperforms other state-of-the-art road detection models and is currently top of the publicly accessible benchmark leader-board.},
	number = {3},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	author = {Chen, Zhe and Zhang, Jing and Tao, Dacheng},
	month = may,
	year = {2019},
	note = {Conference Name: IEEE/CAA Journal of Automatica Sinica},
	keywords = {Feature extraction, Laser radar, Roads, Three-dimensional displays, Transforms, Two dimensional displays, Visualization},
	pages = {693--702},
}

 @misc{malik_lal_2019,

	title={Basic Road Statistics of India [2016-2017]}, 

	url={https://morth.nic.in/sites/default/files/Basic%20_Road_Statics_of_India.pdf}, 

	journal={Basic Road Statistics of India [2016-17]}, 

	publisher={Ministry of Road Transport and Highways}, 

	author={Malik, Yudhvir Singh and Lal, Babni}, 

	year={2019}, 

	month={Mar}
} 


@misc{gps_map,
	title = {Coverage {Map} :: {DynaTrack} {GPS}},
	url = {http://www.dynatrackgps.com/coverage-map.html},
	urldate = {2021-12-16},
	file = {Coverage Map \:\: DynaTrack GPS:/home/autobuntu/snap/zotero-snap/common/Zotero/storage/LIL5UPTF/coverage-map.html:text/html},
}

 @misc{4G_map, 

	title={Wireless 3G / 4G / 5G coverage map, United States}, 
	url={https://www.nperf.com/en/map/US/-/3255.Verizon-Wireless/signal/}, 
	journal={Verizon Wireless 3G / 4G / 5G coverage - nPerf.com}
} 

@inproceedings{Dosovitskiy17,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

 @misc{ntsb, 
	title={Aviation accident database &amp; synopses}, 
	url={https://www.ntsb.gov/_layouts/ntsb.aviation/index.aspx}, 
	journal={NTSB Aviation Accident Database &amp; Synopses}, 
	publisher={FAA William J. Hughes Technical Center Atlantic City International Airport, NJ 08405}, 		year={2021}, 
	month={Nov}
} 
